{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import sklearn\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble,calibration\n",
    "\n",
    "#from sklearn.cross_validation import KFold\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#import pandas, numpy, textblob, string\n",
    "#from keras.preprocessing import text, sequence\n",
    "#from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Turker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "train = pd.read_csv(r'training_matrix.csv')\n",
    "valid = pd.read_csv(r'validating_matrix.csv')\n",
    "test = pd.read_csv(r'testing_matrix.csv')\n",
    "\n",
    "train.loc[train.label == 1, 'label'] = 0\n",
    "train.loc[train.label == -1, 'label'] = 1\n",
    "\n",
    "valid.loc[valid.label == 1, 'label'] = 0\n",
    "valid.loc[valid.label == -1, 'label'] = 1\n",
    "\n",
    "test.loc[test.label == 1, 'label'] = 0\n",
    "test.loc[test.label == -1, 'label'] = 1\n",
    "\n",
    "\n",
    "train['char_count'] = train['review'].apply(len)\n",
    "train['word_count'] = train['review'].apply(lambda x: len(x.split()))\n",
    "train['word_density'] = train['char_count'] / (train['word_count']+1)\n",
    "train['punctuation_count'] = train['review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "train['title_word_count'] = train['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "train['upper_case_word_count'] = train['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "\n",
    "valid['char_count'] = valid['review'].apply(len)\n",
    "valid['word_count'] = valid['review'].apply(lambda x: len(x.split()))\n",
    "valid['word_density'] = valid['char_count'] / (valid['word_count']+1)\n",
    "valid['punctuation_count'] = valid['review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "valid['title_word_count'] = valid['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "valid['upper_case_word_count'] = valid['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "\n",
    "test['char_count'] = test['review'].apply(len)\n",
    "test['word_count'] = test['review'].apply(lambda x: len(x.split()))\n",
    "test['word_density'] = test['char_count'] / (test['word_count']+1)\n",
    "test['punctuation_count'] = test['review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "test['title_word_count'] = test['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "test['upper_case_word_count'] = test['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Day is  Thursday\n",
      "fake is  764\n",
      "real is  755\n",
      "tot is  1519\n",
      "Ratio is  50.29624753127058\n",
      "len is  1519\n",
      "***********Day is  Tuesday\n",
      "fake is  800\n",
      "real is  788\n",
      "tot is  1588\n",
      "Ratio is  50.377833753148614\n",
      "len is  1588\n",
      "***********Day is  Friday\n",
      "fake is  758\n",
      "real is  701\n",
      "tot is  1459\n",
      "Ratio is  51.953392734749826\n",
      "len is  1459\n",
      "***********Day is  Saturday\n",
      "fake is  756\n",
      "real is  744\n",
      "tot is  1500\n",
      "Ratio is  50.4\n",
      "len is  1500\n",
      "***********Day is  Monday\n",
      "fake is  858\n",
      "real is  913\n",
      "tot is  1771\n",
      "Ratio is  48.4472049689441\n",
      "len is  1771\n",
      "***********Day is  Sunday\n",
      "fake is  790\n",
      "real is  903\n",
      "tot is  1693\n",
      "Ratio is  46.66272888363851\n",
      "len is  1693\n",
      "***********Day is  Wednesday\n",
      "fake is  836\n",
      "real is  758\n",
      "tot is  1594\n",
      "Ratio is  52.446675031367626\n",
      "len is  1594\n",
      "***********Day is  Tuesday\n",
      "fake is  150\n",
      "real is  161\n",
      "tot is  311\n",
      "Ratio is  48.231511254019296\n",
      "len is  311\n",
      "***********Day is  Thursday\n",
      "fake is  129\n",
      "real is  128\n",
      "tot is  257\n",
      "Ratio is  50.19455252918288\n",
      "len is  257\n",
      "***********Day is  Saturday\n",
      "fake is  137\n",
      "real is  117\n",
      "tot is  254\n",
      "Ratio is  53.937007874015755\n",
      "len is  254\n",
      "***********Day is  Monday\n",
      "fake is  169\n",
      "real is  166\n",
      "tot is  335\n",
      "Ratio is  50.44776119402985\n",
      "len is  335\n",
      "***********Day is  Wednesday\n",
      "fake is  159\n",
      "real is  141\n",
      "tot is  300\n",
      "Ratio is  53.0\n",
      "len is  300\n",
      "***********Day is  Sunday\n",
      "fake is  138\n",
      "real is  153\n",
      "tot is  291\n",
      "Ratio is  47.42268041237113\n",
      "len is  291\n",
      "***********Day is  Friday\n",
      "fake is  118\n",
      "real is  134\n",
      "tot is  252\n",
      "Ratio is  46.82539682539682\n",
      "len is  252\n",
      "***********Day is  Friday\n",
      "fake is  661\n",
      "real is  638\n",
      "tot is  1299\n",
      "Ratio is  50.88529638183218\n",
      "len is  1299\n",
      "***********Day is  Wednesday\n",
      "fake is  728\n",
      "real is  637\n",
      "tot is  1365\n",
      "Ratio is  53.333333333333336\n",
      "len is  1365\n",
      "***********Day is  Tuesday\n",
      "fake is  754\n",
      "real is  734\n",
      "tot is  1488\n",
      "Ratio is  50.67204301075269\n",
      "len is  1488\n",
      "***********Day is  Sunday\n",
      "fake is  704\n",
      "real is  807\n",
      "tot is  1511\n",
      "Ratio is  46.591661151555265\n",
      "len is  1511\n",
      "***********Day is  Saturday\n",
      "fake is  638\n",
      "real is  660\n",
      "tot is  1298\n",
      "Ratio is  49.152542372881356\n",
      "len is  1298\n",
      "***********Day is  Thursday\n",
      "fake is  681\n",
      "real is  645\n",
      "tot is  1326\n",
      "Ratio is  51.35746606334841\n",
      "len is  1326\n",
      "***********Day is  Monday\n",
      "fake is  834\n",
      "real is  879\n",
      "tot is  1713\n",
      "Ratio is  48.68651488616462\n",
      "len is  1713\n"
     ]
    }
   ],
   "source": [
    "# reviewer_centric features #\n",
    "#train.user_id.value_counts()\n",
    "\n",
    "train['date.1'] = pd.to_datetime(train['date.1'])\n",
    "train['day_of_week'] = train['date.1'].dt.day_name()\n",
    "#train.day_of_week.value_counts()[:10]]\n",
    "dofw = train.day_of_week.unique()\n",
    "for day in range(len(dofw)):\n",
    "        label=train['label'][train.day_of_week == dofw[day]]\n",
    "        fake=len(label[label==1])\n",
    "        real=len(label[label==0])\n",
    "        \n",
    "        print(\"***********Day is \",dofw[day])\n",
    "        print(\"fake is \",fake)\n",
    "        print(\"real is \",real)\n",
    "        print(\"tot is \",fake+real)\n",
    "        print(\"Ratio is \",100*(fake/(fake+real)))\n",
    "        print(\"len is \",len(label))\n",
    "\n",
    "train['user_id_no_of_review'] = train.groupby('user_id')['user_id'].transform('size')\n",
    "train['user_id_ave_rating'] = train.groupby('user_id')['rating'].transform('mean')\n",
    "#train['user_id_std_rating'] = train.groupby('user_id')['rating'].transform('std')\n",
    "train['user_id_ave_no_words'] = train.groupby('user_id')['word_count'].transform('mean')\n",
    "train['user_id_max_review_a_day'] = train['user_id_no_of_review']\n",
    "grouped = train.groupby('user_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    #print(name)\n",
    "    #print(group)\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    #print(df2)\n",
    "    train.loc[train.user_id == name,'user_id_max_review_a_day'] = df2\n",
    "    #group['user_id_max_review_a_day']=df2\n",
    "\n",
    "#train[:][train.user_id==9236].sort_index(axis = 0)\n",
    "    \n",
    "valid['date.1'] = pd.to_datetime(valid['date.1'])\n",
    "valid['day_of_week'] = valid['date.1'].dt.day_name()\n",
    "#valid.day_of_week.value_counts()[:10]]\n",
    "dofw = valid.day_of_week.unique()\n",
    "for day in range(len(dofw)):\n",
    "        label=valid['label'][valid.day_of_week == dofw[day]]\n",
    "        fake=len(label[label==1])\n",
    "        real=len(label[label==0])\n",
    "        \n",
    "        print(\"***********Day is \",dofw[day])\n",
    "        print(\"fake is \",fake)\n",
    "        print(\"real is \",real)\n",
    "        print(\"tot is \",fake+real)\n",
    "        print(\"Ratio is \",100*(fake/(fake+real)))\n",
    "        print(\"len is \",len(label))\n",
    "\n",
    "valid['user_id_no_of_review'] = valid.groupby('user_id')['user_id'].transform('size')\n",
    "valid['user_id_ave_rating'] = valid.groupby('user_id')['rating'].transform('mean')\n",
    "#valid['user_id_std_rating'] = valid.groupby('user_id')['rating'].transform('std')\n",
    "valid['user_id_ave_no_words'] = valid.groupby('user_id')['word_count'].transform('mean')\n",
    "valid['user_id_max_review_a_day'] = valid['user_id_no_of_review']\n",
    "grouped = valid.groupby('user_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    #print(name)\n",
    "    #print(group)\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    #print(df2)\n",
    "    valid.loc[valid.user_id == name,'user_id_max_review_a_day'] = df2\n",
    "    #group['user_id_max_review_a_day']=df2\n",
    "\n",
    "#valid[:][valid.user_id==9236].sort_index(axis = 0) \n",
    "\n",
    "test['date.1'] = pd.to_datetime(test['date.1'])\n",
    "test['day_of_week'] = test['date.1'].dt.day_name()\n",
    "#test.day_of_week.value_counts()[:10]]\n",
    "dofw = test.day_of_week.unique()\n",
    "for day in range(len(dofw)):\n",
    "        label=test['label'][test.day_of_week == dofw[day]]\n",
    "        fake=len(label[label==1])\n",
    "        real=len(label[label==0])\n",
    "        \n",
    "        print(\"***********Day is \",dofw[day])\n",
    "        print(\"fake is \",fake)\n",
    "        print(\"real is \",real)\n",
    "        print(\"tot is \",fake+real)\n",
    "        print(\"Ratio is \",100*(fake/(fake+real)))\n",
    "        print(\"len is \",len(label))\n",
    "\n",
    "test['user_id_no_of_review'] = test.groupby('user_id')['user_id'].transform('size')\n",
    "test['user_id_ave_rating'] = test.groupby('user_id')['rating'].transform('mean')\n",
    "#test['user_id_std_rating'] = test.groupby('user_id')['rating'].transform('std')\n",
    "test['user_id_ave_no_words'] = test.groupby('user_id')['word_count'].transform('mean')\n",
    "test['user_id_max_review_a_day'] = test['user_id_no_of_review']\n",
    "grouped = test.groupby('user_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    #print(name)\n",
    "    #print(group)\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    #print(df2)\n",
    "    test.loc[test.user_id == name,'user_id_max_review_a_day'] = df2\n",
    "    #group['user_id_max_review_a_day']=df2\n",
    "\n",
    "#test[:][test.user_id==9236].sort_index(axis = 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_centric features #\n",
    "#train.prod_id.value_counts()\n",
    "\n",
    "train['prod_id_no_of_review'] = train.groupby('prod_id')['prod_id'].transform('size') + 1000.\n",
    "train['prod_id_ave_rating'] = train.groupby('prod_id')['rating'].transform('mean') + 1000.\n",
    "#train['prod_id_std_rating'] = train.groupby('prod_id')['rating'].transform('std') + 1000.\n",
    "train['prod_id_ave_no_words'] = train.groupby('prod_id')['word_count'].transform('mean') + 1000.\n",
    "train['prod_id_max_review_a_day'] = train['prod_id_no_of_review'] + 1000.\n",
    "grouped = train.groupby('prod_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    #print(name)\n",
    "    #print(group)\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    #print(df2)\n",
    "    train.loc[train.prod_id == name,'prod_id_max_review_a_day'] = df2 + 1000.\n",
    "    #group['prod_id_max_review_a_day']=df2\n",
    "\n",
    "#train[:][train.prod_id==9236].sort_index(axis = 0)\n",
    "\n",
    "valid['prod_id_no_of_review'] = valid.groupby('prod_id')['prod_id'].transform('size') + 1000.\n",
    "valid['prod_id_ave_rating'] = valid.groupby('prod_id')['rating'].transform('mean') + 1000.\n",
    "#valid['prod_id_std_rating'] = valid.groupby('prod_id')['rating'].transform('std') + 1000.\n",
    "valid['prod_id_ave_no_words'] = valid.groupby('prod_id')['word_count'].transform('mean') + 1000.\n",
    "valid['prod_id_max_review_a_day'] = valid['prod_id_no_of_review']\n",
    "grouped = valid.groupby('prod_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    #print(name)\n",
    "    #print(group)\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    #print(df2)\n",
    "    valid.loc[valid.prod_id == name,'prod_id_max_review_a_day'] = df2 + 1000.\n",
    "    #group['prod_id_max_review_a_day']=df2\n",
    "\n",
    "#valid[:][valid.prod_id==9236].sort_index(axis = 0)  \n",
    "\n",
    "test['prod_id_no_of_review'] = test.groupby('prod_id')['prod_id'].transform('size') + 1000.\n",
    "test['prod_id_ave_rating'] = test.groupby('prod_id')['rating'].transform('mean') + 1000.\n",
    "#test['prod_id_std_rating'] = test.groupby('prod_id')['rating'].transform('std') + 1000.\n",
    "test['prod_id_ave_no_words'] = test.groupby('prod_id')['word_count'].transform('mean') + 1000.\n",
    "test['prod_id_max_review_a_day'] = test['prod_id_no_of_review']\n",
    "grouped = test.groupby('prod_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    #print(name)\n",
    "    #print(group)\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    #print(df2)\n",
    "    test.loc[test.prod_id == name,'prod_id_max_review_a_day'] = df2 + 1000.\n",
    "    #group['prod_id_max_review_a_day']=df2\n",
    "\n",
    "#test[:][test.prod_id==9236].sort_index(axis = 0)  \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['total']=train.user_id.astype(str) + ' '+ train.prod_id.astype(str) + ' ' + train.rating.astype(str) + ' '+ \\\n",
    "train.user_id_no_of_review.astype(str) + ' ' + train.user_id_ave_rating.astype(str) + ' '+\\\n",
    "train.user_id_ave_no_words.astype(str) + ' ' + train.user_id_max_review_a_day.astype(str) + ' '+\\\n",
    "train.prod_id_no_of_review.astype(str) + ' ' + train.prod_id_ave_rating.astype(str) + ' '+\\\n",
    "train.prod_id_ave_no_words.astype(str) + ' ' + train.prod_id_max_review_a_day.astype(str) + ' '+\\\n",
    "train.day_of_week.astype(str) + ' '+train.review  \n",
    "\n",
    "#train['total']=train.user_id.astype(str) + ' '+ train.prod_id.astype(str) + ' ' + train.rating.astype(str) + ' '+  train.review\n",
    "#test['total']=test.user_id.astype(str) + ' '+ test.prod_id.astype(str) + ' ' + test.rating.astype(str) + ' '+test.review\n",
    "\n",
    "valid['total']=valid.user_id.astype(str) + ' '+ valid.prod_id.astype(str) + ' ' + valid.rating.astype(str) + ' '+ \\\n",
    "valid.user_id_no_of_review.astype(str) + ' ' + valid.user_id_ave_rating.astype(str) + ' '+\\\n",
    "valid.user_id_ave_no_words.astype(str) + ' ' + valid.user_id_max_review_a_day.astype(str) + ' '+\\\n",
    "valid.prod_id_no_of_review.astype(str) + ' ' + valid.prod_id_ave_rating.astype(str) + ' '+\\\n",
    "valid.prod_id_ave_no_words.astype(str) + ' ' + valid.prod_id_max_review_a_day.astype(str) + ' '+\\\n",
    "valid.day_of_week.astype(str) + ' '+ valid.review  \n",
    "\n",
    "test['total']=test.user_id.astype(str) + ' '+ test.prod_id.astype(str) + ' ' + test.rating.astype(str) + ' '+ \\\n",
    "test.user_id_no_of_review.astype(str) + ' ' + test.user_id_ave_rating.astype(str) + ' '+\\\n",
    "test.user_id_ave_no_words.astype(str) + ' ' + test.user_id_max_review_a_day.astype(str) + ' '+\\\n",
    "test.prod_id_no_of_review.astype(str) + ' ' + test.prod_id_ave_rating.astype(str) + ' '+\\\n",
    "test.prod_id_ave_no_words.astype(str) + ' ' + test.prod_id_max_review_a_day.astype(str) + ' '+\\\n",
    "test.day_of_week.astype(str) + ' '+ test.review  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Turker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import SnowballStemmer\n",
    "porter = SnowballStemmer(\"english\")\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from scipy import sparse\n",
    "def apply_PCA(feature_vector_train, feature_vector_valid, feature_vector_test, n_components = 300):\n",
    "    # applys PCA\n",
    "    pca = PCA(n_components)\n",
    "    #pca = PCA(0.95)\n",
    "    pca.fit(feature_vector_train.toarray())\n",
    "    xtrain = pca.transform(feature_vector_train.toarray())  \n",
    "    xvalid = pca.transform(feature_vector_valid.toarray())       \n",
    "    xtest  = pca.transform(feature_vector_test.toarray()) \n",
    "    \n",
    "    feature_vector_train = sparse.csr_matrix(xtrain)\n",
    "    feature_vector_valid = sparse.csr_matrix(xvalid)\n",
    "    feature_vector_test  = sparse.csr_matrix(xtest)    \n",
    "    \n",
    "    return [feature_vector_train, feature_vector_valid, feature_vector_test]\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "def apply_LDA(feature_vector_train, feature_vector_valid, feature_vector_test, n_components = 300):\n",
    "    # applys lda\n",
    "    lda = LatentDirichletAllocation(n_components, random_state=0)\n",
    "    lda.fit(feature_vector_train.toarray())\n",
    "    xtrain = lda.transform(feature_vector_train.toarray())  \n",
    "    xvalid = lda.transform(feature_vector_valid.toarray())       \n",
    "    xtest  = lda.transform(feature_vector_test.toarray()) \n",
    "    \n",
    "    feature_vector_train = sparse.csr_matrix(xtrain)\n",
    "    feature_vector_valid = sparse.csr_matrix(xvalid)\n",
    "    feature_vector_test  = sparse.csr_matrix(xtest)    \n",
    "    \n",
    "    return [feature_vector_train, feature_vector_valid, feature_vector_test]\n",
    "\n",
    "\n",
    "def scale_feature(col):\n",
    "    x = col.values.astype(float)\n",
    "    # Create a minimum and maximum processor object\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()    \n",
    "    # Create an object to transform the data to fit minmax processor\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    col = x_scaled\n",
    "    return col\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "def add_features(feature_vector_train, feature_vector_valid, feature_vector_test):\n",
    "    \n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['user_id_no_of_review'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['user_id_ave_rating'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['user_id_ave_no_words'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['user_id_max_review_a_day'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['prod_id_no_of_review'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['prod_id_ave_rating'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['prod_id_ave_no_words'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['prod_id_max_review_a_day'])[:,None]))    \n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['char_count'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['word_count'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['word_density'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['punctuation_count'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['title_word_count'])[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(train['upper_case_word_count'])[:,None]))\n",
    "    \n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['user_id_no_of_review'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['user_id_ave_rating'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['user_id_ave_no_words'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['user_id_max_review_a_day'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['prod_id_no_of_review'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['prod_id_ave_rating'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['prod_id_ave_no_words'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['prod_id_max_review_a_day'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['char_count'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['word_count'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['word_density'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['punctuation_count'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['title_word_count'])[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(valid['upper_case_word_count'])[:,None]))\n",
    "    \n",
    "    \n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['user_id_no_of_review'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['user_id_ave_rating'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['user_id_ave_no_words'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['user_id_max_review_a_day'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['prod_id_no_of_review'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['prod_id_ave_rating'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['prod_id_ave_no_words'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['prod_id_max_review_a_day'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['char_count'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['word_count'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['word_density'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['punctuation_count'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['title_word_count'])[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(test['upper_case_word_count'])[:,None]))\n",
    "    \n",
    "    return [feature_vector_train, feature_vector_valid, feature_vector_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "#count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000, stop_words='english')\n",
    "#count_vect.fit(train.total)\n",
    "#\n",
    "#x_train_count =  count_vect.transform(train.total)\n",
    "#x_valid_count =  count_vect.transform(valid.total)\n",
    "#x_test_count =  count_vect.transform(test.total)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=5000, stop_words='english',min_df=5)\n",
    "tfidf_vect_ngram.fit(train.review)\n",
    "x_train_tfidf_ngram =  tfidf_vect_ngram.transform(train.review)\n",
    "x_valid_tfidf_ngram =  tfidf_vect_ngram.transform(valid.review)\n",
    "x_test_tfidf_ngram =  tfidf_vect_ngram.transform(test.review)\n",
    "\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram_NB = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=5000, stop_words='english',min_df=5)\n",
    "tfidf_vect_ngram_NB.fit(train.total)\n",
    "x_train_tfidf_ngram_NB =  tfidf_vect_ngram_NB.transform(train.total)\n",
    "x_valid_tfidf_ngram_NB =  tfidf_vect_ngram_NB.transform(valid.total)\n",
    "x_test_tfidf_ngram_NB =  tfidf_vect_ngram_NB.transform(test.total)\n",
    "#[x_train_tfidf_ngram, x_test_tfidf_ngram] = apply_PCA(x_train_tfidf_ngram, x_test_tfidf_ngram)\n",
    "#[x_train_tfidf_ngram, x_test_tfidf_ngram] = add_features(x_train_tfidf_ngram, x_test_tfidf_ngram)\n",
    "\n",
    "\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid,label_valid, is_neural_net=False):\n",
    "    # fit the train dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    # predict the labels on validation dataset\n",
    "    probs = classifier.predict_proba(feature_vector_valid)\n",
    "    #print(\"Probs is \",probs[:,1])\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    return [predictions,metrics.accuracy_score(predictions, label_valid),probs]\n",
    "\n",
    "## Create first pipeline for base without reducing features.\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#\n",
    "#pipe = Pipeline([('classifier' , linear_model.LogisticRegression())])\n",
    "## pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
    "##lr = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ NB Test***********\n",
      "Accuracy is   0.6386\n",
      "Auc ROC is  0.69255616\n",
      "Auc PRC is  0.6647269111392298\n",
      "F1 score is 0.65396399846802\n",
      "Log loss is  0.6335912741332487\n",
      "************ NB Valid***********\n",
      "Accuracy is   0.657\n",
      "Auc ROC is  0.703815\n",
      "Auc PRC is  0.6764445297129313\n",
      "F1 score is 0.6669902912621359\n",
      "Log loss is  0.6282846644737022\n",
      "************ NB Train***********\n",
      "Accuracy is   0.7304027328299173\n",
      "Auc ROC is  0.8016306262728762\n",
      "Auc PRC is  0.786762282790817\n",
      "F1 score is 0.7336826214368173\n",
      "Log loss is  0.568375774958194\n"
     ]
    }
   ],
   "source": [
    "train_y=train.label\n",
    "test_y=test.label\n",
    "valid_y=valid.label\n",
    "\n",
    "\n",
    "train_x=x_train_tfidf_ngram\n",
    "test_x=x_test_tfidf_ngram\n",
    "valid_x=x_valid_tfidf_ngram\n",
    "print(\"************ NB Test***********\")\n",
    "\n",
    "[predictions,accuracy,probs] = train_model(naive_bayes.MultinomialNB(), train_x, train_y, test_x, test_y)\n",
    "print (\"Accuracy is  \", accuracy)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_y, probs[:,1])\n",
    "auc = metrics.roc_auc_score(test_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc)\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(test_y, probs[:,1])\n",
    "auc = metrics.auc(recall, precision)\n",
    "print(\"Auc PRC is \",auc)\n",
    "f1 = metrics.f1_score(test_y, predictions)\n",
    "print(\"F1 score is\",f1)\n",
    "print(\"Log loss is \",metrics.log_loss(test_y,probs[:,1]))\n",
    "\n",
    "print(\"************ NB Valid***********\")\n",
    "\n",
    "[predictions,accuracy,probs] = train_model(naive_bayes.MultinomialNB(), train_x, train_y, valid_x, valid_y)\n",
    "print (\"Accuracy is  \", accuracy)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(valid_y, probs[:,1])\n",
    "auc = metrics.roc_auc_score(valid_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc)\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(valid_y, probs[:,1])\n",
    "auc = metrics.auc(recall, precision)\n",
    "print(\"Auc PRC is \",auc)\n",
    "f1 = metrics.f1_score(valid_y, predictions)\n",
    "print(\"F1 score is\",f1)\n",
    "print(\"Log loss is \",metrics.log_loss(valid_y,probs[:,1]))\n",
    "\n",
    "print(\"************ NB Train***********\")\n",
    "\n",
    "[predictions,accuracy,probs] = train_model(naive_bayes.MultinomialNB(), train_x, train_y, train_x, train_y)\n",
    "print (\"Accuracy is  \", accuracy)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(train_y, probs[:,1])\n",
    "auc = metrics.roc_auc_score(train_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc)\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(train_y, probs[:,1])\n",
    "auc = metrics.auc(recall, precision)\n",
    "print(\"Auc PRC is \",auc)\n",
    "f1 = metrics.f1_score(train_y, predictions)\n",
    "print(\"F1 score is\",f1)\n",
    "print(\"Log loss is \",metrics.log_loss(train_y,probs[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ NB Test***********\n",
      "Accuracy is   0.6544\n",
      "Auc ROC is  0.7080433199999999\n",
      "Auc PRC is  0.6695996516929208\n",
      "F1 score is 0.680709534368071\n",
      "Log loss is  0.6241664904935046\n",
      "recall_score score is 0.7368\n",
      "precision_score score is 0.632554945054945\n",
      "************ NB Valid***********\n",
      "Accuracy is   0.657\n",
      "Auc ROC is  0.71219\n",
      "Auc PRC is  0.6841077278045159\n",
      "F1 score is 0.6815227483751161\n",
      "Log loss is  0.6222970418207876\n",
      "************ NB Train***********\n",
      "Accuracy is   0.7088277597986335\n",
      "Auc ROC is  0.7765207246325654\n",
      "Auc PRC is  0.7582896850135389\n",
      "F1 score is 0.7164492690186466\n",
      "Log loss is  0.5695794416704953\n"
     ]
    }
   ],
   "source": [
    "train_x=x_train_tfidf_ngram_NB\n",
    "test_x=x_test_tfidf_ngram_NB\n",
    "valid_x=x_valid_tfidf_ngram_NB\n",
    "print(\"************ NB Test***********\")\n",
    "\n",
    "[predictions,accuracy,probs] = train_model(naive_bayes.MultinomialNB(), train_x, train_y, test_x, test_y)\n",
    "print (\"Accuracy is  \", accuracy)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_y, probs[:,1])\n",
    "auc = metrics.roc_auc_score(test_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc)\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(test_y, probs[:,1])\n",
    "auc = metrics.auc(recall, precision)\n",
    "print(\"Auc PRC is \",auc)\n",
    "f1 = metrics.f1_score(test_y, predictions)\n",
    "print(\"F1 score is\",f1)\n",
    "print(\"Log loss is \",metrics.log_loss(test_y,probs[:,1]))\n",
    "\n",
    "recall_score = metrics.recall_score(test_y, predictions)\n",
    "print(\"recall_score score is\",recall_score)\n",
    "precision_score = metrics.precision_score(test_y, predictions)\n",
    "print(\"precision_score score is\",precision_score)\n",
    "\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['prob'] = probs[:,1]\n",
    "results['predictions'] = predictions\n",
    "results['labels'] = test_y\n",
    "results.to_csv(('NB.csv'))\n",
    "\n",
    "\n",
    "print(\"************ NB Valid***********\")\n",
    "\n",
    "[predictions,accuracy,probs] = train_model(naive_bayes.MultinomialNB(), train_x, train_y, valid_x, valid_y)\n",
    "print (\"Accuracy is  \", accuracy)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(valid_y, probs[:,1])\n",
    "auc = metrics.roc_auc_score(valid_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc)\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(valid_y, probs[:,1])\n",
    "auc = metrics.auc(recall, precision)\n",
    "print(\"Auc PRC is \",auc)\n",
    "f1 = metrics.f1_score(valid_y, predictions)\n",
    "print(\"F1 score is\",f1)\n",
    "print(\"Log loss is \",metrics.log_loss(valid_y,probs[:,1]))\n",
    "\n",
    "print(\"************ NB Train***********\")\n",
    "\n",
    "[predictions,accuracy,probs] = train_model(naive_bayes.MultinomialNB(), train_x, train_y, train_x, train_y)\n",
    "print (\"Accuracy is  \", accuracy)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(train_y, probs[:,1])\n",
    "auc = metrics.roc_auc_score(train_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc)\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(train_y, probs[:,1])\n",
    "auc = metrics.auc(recall, precision)\n",
    "print(\"Auc PRC is \",auc)\n",
    "f1 = metrics.f1_score(train_y, predictions)\n",
    "print(\"F1 score is\",f1)\n",
    "print(\"Log loss is \",metrics.log_loss(train_y,probs[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
