{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import sklearn\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble,calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Khaled\n",
      "[nltk_data]     Aounallah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "def add_features(feature_vector_train, feature_vector_valid,feature_vector_test):\n",
    "   \n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['prod_id']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['rating']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['user_id_no_of_review']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['user_id_ave_rating']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['user_id_ave_no_words']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['user_id_max_review_a_day']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['prod_id_no_of_review']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['prod_id_ave_rating']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['prod_id_ave_no_words']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['prod_id_max_review_a_day']))[:,None]))    \n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['char_count']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['word_count']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['word_density']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['punctuation_count']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['title_word_count']))[:,None]))\n",
    "    feature_vector_train = hstack((feature_vector_train,np.array(minmax_scale(training['upper_case_word_count']))[:,None]))\n",
    "   \n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['prod_id']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['rating']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['user_id_no_of_review']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['user_id_ave_rating']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['user_id_ave_no_words']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['user_id_max_review_a_day']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['prod_id_no_of_review']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['prod_id_ave_rating']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['prod_id_ave_no_words']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['prod_id_max_review_a_day']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['char_count']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['word_count']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['word_density']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['punctuation_count']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['title_word_count']))[:,None]))\n",
    "    feature_vector_valid = hstack((feature_vector_valid,np.array(minmax_scale(testing['upper_case_word_count']))[:,None]))\n",
    "   \n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['prod_id']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['rating']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['user_id_no_of_review']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['user_id_ave_rating']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['user_id_ave_no_words']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['user_id_max_review_a_day']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['prod_id_no_of_review']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['prod_id_ave_rating']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['prod_id_ave_no_words']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['prod_id_max_review_a_day']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['char_count']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['word_count']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['word_density']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['punctuation_count']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['title_word_count']))[:,None]))\n",
    "    feature_vector_test = hstack((feature_vector_test,np.array(minmax_scale(final_testing['upper_case_word_count']))[:,None]))\n",
    "   \n",
    "    return [feature_vector_train, feature_vector_valid, feature_vector_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=pd.read_csv(r'training_matrix.csv',header=0,index_col=0)\n",
    "testing=pd.read_csv(r'testing_matrix.csv',header=0,index_col=0)\n",
    "final_testing=pd.read_csv('final_testing.csv',header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.loc[training.label == 1, 'label'] = 0\n",
    "training.loc[training.label == -1, 'label'] = 1\n",
    "\n",
    "testing.loc[testing.label == 1, 'label'] = 0\n",
    "testing.loc[testing.label == -1, 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['char_count'] = training['review'].apply(len)\n",
    "training['word_count'] = training['review'].apply(lambda x: len(x.split()))\n",
    "training['word_density'] = training['char_count'] / (training['word_count']+1)\n",
    "training['punctuation_count'] = training['review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "training['title_word_count'] = training['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "training['upper_case_word_count'] = training['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['char_count'] = testing['review'].apply(len)\n",
    "testing['word_count'] = testing['review'].apply(lambda x: len(x.split()))\n",
    "testing['word_density'] = testing['char_count'] / (testing['word_count']+1)\n",
    "testing['punctuation_count'] = testing['review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "testing['title_word_count'] = testing['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "testing['upper_case_word_count'] = testing['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Reviewer Centric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Day is  Thursday\n",
      "fake is  764\n",
      "real is  755\n",
      "tot is  1519\n",
      "Ratio is  50.29624753127058\n",
      "len is  1519\n",
      "***********Day is  Tuesday\n",
      "fake is  800\n",
      "real is  788\n",
      "tot is  1588\n",
      "Ratio is  50.377833753148614\n",
      "len is  1588\n",
      "***********Day is  Friday\n",
      "fake is  758\n",
      "real is  701\n",
      "tot is  1459\n",
      "Ratio is  51.953392734749826\n",
      "len is  1459\n",
      "***********Day is  Saturday\n",
      "fake is  756\n",
      "real is  744\n",
      "tot is  1500\n",
      "Ratio is  50.4\n",
      "len is  1500\n",
      "***********Day is  Monday\n",
      "fake is  858\n",
      "real is  913\n",
      "tot is  1771\n",
      "Ratio is  48.4472049689441\n",
      "len is  1771\n",
      "***********Day is  Sunday\n",
      "fake is  790\n",
      "real is  903\n",
      "tot is  1693\n",
      "Ratio is  46.66272888363851\n",
      "len is  1693\n",
      "***********Day is  Wednesday\n",
      "fake is  836\n",
      "real is  758\n",
      "tot is  1594\n",
      "Ratio is  52.446675031367626\n",
      "len is  1594\n",
      "***********Day is  Tuesday\n",
      "fake is  150\n",
      "real is  161\n",
      "tot is  311\n",
      "Ratio is  48.231511254019296\n",
      "len is  311\n",
      "***********Day is  Thursday\n",
      "fake is  129\n",
      "real is  128\n",
      "tot is  257\n",
      "Ratio is  50.19455252918288\n",
      "len is  257\n",
      "***********Day is  Saturday\n",
      "fake is  137\n",
      "real is  117\n",
      "tot is  254\n",
      "Ratio is  53.937007874015755\n",
      "len is  254\n",
      "***********Day is  Monday\n",
      "fake is  169\n",
      "real is  166\n",
      "tot is  335\n",
      "Ratio is  50.44776119402985\n",
      "len is  335\n",
      "***********Day is  Wednesday\n",
      "fake is  159\n",
      "real is  141\n",
      "tot is  300\n",
      "Ratio is  53.0\n",
      "len is  300\n",
      "***********Day is  Sunday\n",
      "fake is  138\n",
      "real is  153\n",
      "tot is  291\n",
      "Ratio is  47.42268041237113\n",
      "len is  291\n",
      "***********Day is  Friday\n",
      "fake is  118\n",
      "real is  134\n",
      "tot is  252\n",
      "Ratio is  46.82539682539682\n",
      "len is  252\n"
     ]
    }
   ],
   "source": [
    "training['date.1'] = pd.to_datetime(training['date.1'])\n",
    "training['day_of_week'] = training['date.1'].dt.day_name()\n",
    "dofw = training.day_of_week.unique()\n",
    "for day in range(len(dofw)):\n",
    "        label=training['label'][training.day_of_week == dofw[day]]\n",
    "        fake=len(label[label==1])\n",
    "        real=len(label[label==0])\n",
    "        \n",
    "        print(\"***********Day is \",dofw[day])\n",
    "        print(\"fake is \",fake)\n",
    "        print(\"real is \",real)\n",
    "        print(\"tot is \",fake+real)\n",
    "        print(\"Ratio is \",100*(fake/(fake+real)))\n",
    "        print(\"len is \",len(label))\n",
    "\n",
    "training['user_id_no_of_review'] = training.groupby('user_id')['user_id'].transform('size')\n",
    "training['user_id_ave_rating'] = training.groupby('user_id')['rating'].transform('mean')\n",
    "training['user_id_ave_no_words'] = training.groupby('user_id')['word_count'].transform('mean')\n",
    "training['user_id_max_review_a_day'] = training['user_id_no_of_review']\n",
    "grouped = training.groupby('user_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    training.loc[training.user_id == name,'user_id_max_review_a_day'] = df2\n",
    "\n",
    "testing['date.1'] = pd.to_datetime(testing['date.1'])\n",
    "testing['day_of_week'] = testing['date.1'].dt.day_name()\n",
    "dofw = testing.day_of_week.unique()\n",
    "for day in range(len(dofw)):\n",
    "        label=testing['label'][testing.day_of_week == dofw[day]]\n",
    "        fake=len(label[label==1])\n",
    "        real=len(label[label==0])\n",
    "        \n",
    "        print(\"***********Day is \",dofw[day])\n",
    "        print(\"fake is \",fake)\n",
    "        print(\"real is \",real)\n",
    "        print(\"tot is \",fake+real)\n",
    "        print(\"Ratio is \",100*(fake/(fake+real)))\n",
    "        print(\"len is \",len(label))\n",
    "\n",
    "testing['user_id_no_of_review'] = testing.groupby('user_id')['user_id'].transform('size')\n",
    "testing['user_id_ave_rating'] = testing.groupby('user_id')['rating'].transform('mean')\n",
    "testing['user_id_ave_no_words'] = testing.groupby('user_id')['word_count'].transform('mean')\n",
    "testing['user_id_max_review_a_day'] = testing['user_id_no_of_review']\n",
    "grouped = testing.groupby('user_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    testing.loc[testing.user_id == name,'user_id_max_review_a_day'] = df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Centric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>date.1</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>rating</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>...</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>user_id_no_of_review</th>\n",
       "      <th>user_id_ave_rating</th>\n",
       "      <th>user_id_ave_no_words</th>\n",
       "      <th>user_id_max_review_a_day</th>\n",
       "      <th>prod_id_no_of_review</th>\n",
       "      <th>prod_id_ave_rating</th>\n",
       "      <th>prod_id_ave_no_words</th>\n",
       "      <th>prod_id_max_review_a_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-02</th>\n",
       "      <td>89977</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>Coming from the Bay area where we do have some...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>902</td>\n",
       "      <td>167</td>\n",
       "      <td>5.369048</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>94310</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>This ain't no hole in the wall ramen spot. Thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>970</td>\n",
       "      <td>183</td>\n",
       "      <td>5.271739</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>157513</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>Whenever I have friends in own, this is one of...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>340</td>\n",
       "      <td>68</td>\n",
       "      <td>4.927536</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-09</th>\n",
       "      <td>29568</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-09</td>\n",
       "      <td>You come here to say you did. Food: Pork buns ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1228</td>\n",
       "      <td>222</td>\n",
       "      <td>5.506726</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-09</th>\n",
       "      <td>22455</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-09</td>\n",
       "      <td>Joining a league of thousands...I am adding my...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2092</td>\n",
       "      <td>369</td>\n",
       "      <td>5.654054</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-12</th>\n",
       "      <td>29562</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-12</td>\n",
       "      <td>We ended up choosing Ippudo in the Village. Go...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>701</td>\n",
       "      <td>136</td>\n",
       "      <td>5.116788</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>164.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-12</th>\n",
       "      <td>96152</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-12</td>\n",
       "      <td>This place is an ABSOLUTE-MUST if you're visit...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2311</td>\n",
       "      <td>423</td>\n",
       "      <td>5.450472</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-14</th>\n",
       "      <td>158876</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-14</td>\n",
       "      <td>First time here... and I liked it!  The noodle...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>607</td>\n",
       "      <td>118</td>\n",
       "      <td>5.100840</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>11744</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>I was doubtful. I've had $1 ramen you buy in s...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1275</td>\n",
       "      <td>240</td>\n",
       "      <td>5.290456</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>13207</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>A must... Ramen is slammin... Worth the wait...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-18</th>\n",
       "      <td>19800</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-18</td>\n",
       "      <td>Went back and got the Kogashi Miso Ramen, and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160</td>\n",
       "      <td>32</td>\n",
       "      <td>4.848485</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-18</th>\n",
       "      <td>158869</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-18</td>\n",
       "      <td>I had lunch there on a Monday, I waited a tabl...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>278</td>\n",
       "      <td>56</td>\n",
       "      <td>4.877193</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-23</th>\n",
       "      <td>74226</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-23</td>\n",
       "      <td>When we got there a few days after Christmas, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>615</td>\n",
       "      <td>118</td>\n",
       "      <td>5.168067</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-23</th>\n",
       "      <td>157407</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-23</td>\n",
       "      <td>I don't know what everyone's hype is about Ipp...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>902</td>\n",
       "      <td>171</td>\n",
       "      <td>5.244186</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-24</th>\n",
       "      <td>111074</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>This is one of the best restaurants I've been ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>395</td>\n",
       "      <td>80</td>\n",
       "      <td>4.876543</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-24</th>\n",
       "      <td>32038</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>I was there twice and the noodle dishes were g...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>560</td>\n",
       "      <td>112</td>\n",
       "      <td>4.955752</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-25</th>\n",
       "      <td>157664</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-25</td>\n",
       "      <td>I really love this place. I go here all the ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>288</td>\n",
       "      <td>62</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-25</th>\n",
       "      <td>157406</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-25</td>\n",
       "      <td>Food are always fresh , U guys must go</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-27</th>\n",
       "      <td>29496</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-27</td>\n",
       "      <td>Came here with two friends, and we had to wait...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>462</td>\n",
       "      <td>86</td>\n",
       "      <td>5.310345</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-27</th>\n",
       "      <td>18205</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-27</td>\n",
       "      <td>GREAT rich, flavorful broth, and as expected w...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>428</td>\n",
       "      <td>78</td>\n",
       "      <td>5.417722</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-28</th>\n",
       "      <td>157663</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-01-28</td>\n",
       "      <td>Yum! This place opened my eyes to a new world ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>376</td>\n",
       "      <td>70</td>\n",
       "      <td>5.295775</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-02</th>\n",
       "      <td>25408</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>Delicious! Most silent meal we ever had becaus...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>178</td>\n",
       "      <td>34</td>\n",
       "      <td>5.085714</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-03</th>\n",
       "      <td>118150</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-02-03</td>\n",
       "      <td>My brother and five of our friends went here a...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1070</td>\n",
       "      <td>213</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-06</th>\n",
       "      <td>22174</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-02-06</td>\n",
       "      <td>Rich, creamy, and VERY satisfying tonkatsu ram...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1658</td>\n",
       "      <td>320</td>\n",
       "      <td>5.165109</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-07</th>\n",
       "      <td>157662</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-02-07</td>\n",
       "      <td>I went here over Christmas with my boyfriend a...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>411</td>\n",
       "      <td>77</td>\n",
       "      <td>5.269231</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-08</th>\n",
       "      <td>158860</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-02-08</td>\n",
       "      <td>Ippudo is great for a date or just a nice rame...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>177</td>\n",
       "      <td>37</td>\n",
       "      <td>4.657895</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-08</th>\n",
       "      <td>157661</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-02-08</td>\n",
       "      <td>the broth tastes like everything good in this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>131</td>\n",
       "      <td>22</td>\n",
       "      <td>5.695652</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-10</th>\n",
       "      <td>158859</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-02-10</td>\n",
       "      <td>Went here with a friend for lunch.  The pork b...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>320</td>\n",
       "      <td>58</td>\n",
       "      <td>5.423729</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-11</th>\n",
       "      <td>94294</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-02-11</td>\n",
       "      <td>The best ramen I've had in the US. I couldn't ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>550</td>\n",
       "      <td>105</td>\n",
       "      <td>5.188679</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-13</th>\n",
       "      <td>55042</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-02-13</td>\n",
       "      <td>I'm definitely a fan.  Ok the price isn't the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>651</td>\n",
       "      <td>125</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-06</th>\n",
       "      <td>2287</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-06</td>\n",
       "      <td>I've been to Ippudo upwards of 8 times now, an...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>626</td>\n",
       "      <td>124</td>\n",
       "      <td>5.008000</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-06</th>\n",
       "      <td>59869</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-06</td>\n",
       "      <td>OK Ippudo, after numerous visits taking all my...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>480</td>\n",
       "      <td>94</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>117.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-08</th>\n",
       "      <td>8981</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-08</td>\n",
       "      <td>I waited for two hours, was bitched at by our ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>165</td>\n",
       "      <td>32</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>6</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>67.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-08</th>\n",
       "      <td>25976</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-08</td>\n",
       "      <td>There was only 2 of us on our party and we wen...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>947</td>\n",
       "      <td>190</td>\n",
       "      <td>4.958115</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-08</th>\n",
       "      <td>158670</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-08</td>\n",
       "      <td>Amazing...   One of my favorite NYC restaurant...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>159</td>\n",
       "      <td>29</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-13</th>\n",
       "      <td>158666</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-13</td>\n",
       "      <td>Love this place every time I go. I'll keep it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>112</td>\n",
       "      <td>23</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-14</th>\n",
       "      <td>1854</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-14</td>\n",
       "      <td>OK OK , everyone, don't get angry. I liked Ipp...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1667</td>\n",
       "      <td>307</td>\n",
       "      <td>5.412338</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>387.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-15</th>\n",
       "      <td>87885</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-15</td>\n",
       "      <td>Absolutely loved this place! From the greeting...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>324</td>\n",
       "      <td>62</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-18</th>\n",
       "      <td>5408</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-18</td>\n",
       "      <td>You may balk at having to wait 60-90mins for a...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>376</td>\n",
       "      <td>71</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>5</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>72.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-21</th>\n",
       "      <td>991</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-21</td>\n",
       "      <td>I strongly advise you to NOT come here on a we...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1315</td>\n",
       "      <td>249</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-22</th>\n",
       "      <td>1748</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-22</td>\n",
       "      <td>Yummy.  Ate here for lunch today. First the wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>252</td>\n",
       "      <td>48</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>86.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-23</th>\n",
       "      <td>10233</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-23</td>\n",
       "      <td>My second time here.  To me, this place is mor...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>369</td>\n",
       "      <td>65</td>\n",
       "      <td>5.590909</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-25</th>\n",
       "      <td>158662</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-25</td>\n",
       "      <td>horrible service, awful hostess and very tight...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-27</th>\n",
       "      <td>15498</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-27</td>\n",
       "      <td>Went a second time, got the same thing, still ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>355</td>\n",
       "      <td>70</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-27</th>\n",
       "      <td>39509</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-11-27</td>\n",
       "      <td>Ippudo has quickly distinguished itself from o...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1427</td>\n",
       "      <td>243</td>\n",
       "      <td>5.848361</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-04</th>\n",
       "      <td>115296</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>Very good ramen.  I like the spice and the noo...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>167</td>\n",
       "      <td>29</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-04</th>\n",
       "      <td>31537</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>This place is good for classic ramen. The plac...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>751</td>\n",
       "      <td>139</td>\n",
       "      <td>5.364286</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-05</th>\n",
       "      <td>128231</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-05</td>\n",
       "      <td>Plan to have lunch early so you can be in line...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1611</td>\n",
       "      <td>304</td>\n",
       "      <td>5.281967</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-07</th>\n",
       "      <td>75458</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-07</td>\n",
       "      <td>The place was way overrated. It's not worth st...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87</td>\n",
       "      <td>17</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-08</th>\n",
       "      <td>16934</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-08</td>\n",
       "      <td>Ippudo is taste same taste between NYC and Jap...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>201</td>\n",
       "      <td>36</td>\n",
       "      <td>5.432432</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>12.363636</td>\n",
       "      <td>5</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-08</th>\n",
       "      <td>81721</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-08</td>\n",
       "      <td>This place was great!  You've got to love a pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>995</td>\n",
       "      <td>183</td>\n",
       "      <td>5.407609</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-14</th>\n",
       "      <td>5852</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-14</td>\n",
       "      <td>Awesome Awesome Ramen. Anytime you go to a pla...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>893</td>\n",
       "      <td>177</td>\n",
       "      <td>5.016854</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-14</th>\n",
       "      <td>57936</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-14</td>\n",
       "      <td>Oh my God!  The best pork buns ever!  Not to m...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>165</td>\n",
       "      <td>32</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-15</th>\n",
       "      <td>158653</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>Only four starts because it was a bit loud wit...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>480</td>\n",
       "      <td>87</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-18</th>\n",
       "      <td>158652</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-18</td>\n",
       "      <td>I have to say....second time around with 2 yea...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1421</td>\n",
       "      <td>262</td>\n",
       "      <td>5.403042</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-18</th>\n",
       "      <td>987</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-18</td>\n",
       "      <td>I swore I would never wait an hour standing in...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>727</td>\n",
       "      <td>148</td>\n",
       "      <td>4.879195</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-27</th>\n",
       "      <td>29241</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-27</td>\n",
       "      <td>I wish I had visited this place a lot more so ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>512</td>\n",
       "      <td>104</td>\n",
       "      <td>4.876190</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-27</th>\n",
       "      <td>157645</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-27</td>\n",
       "      <td>Rainy day in NYC, had just spent 2 hours stand...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>949</td>\n",
       "      <td>172</td>\n",
       "      <td>5.485549</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-29</th>\n",
       "      <td>95951</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-29</td>\n",
       "      <td>I'm giving this 3 stars only because of the po...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2316</td>\n",
       "      <td>437</td>\n",
       "      <td>5.287671</td>\n",
       "      <td>143</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-30</th>\n",
       "      <td>157365</td>\n",
       "      <td>247</td>\n",
       "      <td>2011-12-30</td>\n",
       "      <td>As a person grown up to love noodles, I must s...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1819</td>\n",
       "      <td>336</td>\n",
       "      <td>5.397626</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>118.948936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id  prod_id     date.1  \\\n",
       "date                                      \n",
       "2011-01-02    89977      247 2011-01-02   \n",
       "2011-01-05    94310      247 2011-01-05   \n",
       "2011-01-05   157513      247 2011-01-05   \n",
       "2011-01-09    29568      247 2011-01-09   \n",
       "2011-01-09    22455      247 2011-01-09   \n",
       "2011-01-12    29562      247 2011-01-12   \n",
       "2011-01-12    96152      247 2011-01-12   \n",
       "2011-01-14   158876      247 2011-01-14   \n",
       "2011-01-17    11744      247 2011-01-17   \n",
       "2011-01-17    13207      247 2011-01-17   \n",
       "2011-01-18    19800      247 2011-01-18   \n",
       "2011-01-18   158869      247 2011-01-18   \n",
       "2011-01-23    74226      247 2011-01-23   \n",
       "2011-01-23   157407      247 2011-01-23   \n",
       "2011-01-24   111074      247 2011-01-24   \n",
       "2011-01-24    32038      247 2011-01-24   \n",
       "2011-01-25   157664      247 2011-01-25   \n",
       "2011-01-25   157406      247 2011-01-25   \n",
       "2011-01-27    29496      247 2011-01-27   \n",
       "2011-01-27    18205      247 2011-01-27   \n",
       "2011-01-28   157663      247 2011-01-28   \n",
       "2011-02-02    25408      247 2011-02-02   \n",
       "2011-02-03   118150      247 2011-02-03   \n",
       "2011-02-06    22174      247 2011-02-06   \n",
       "2011-02-07   157662      247 2011-02-07   \n",
       "2011-02-08   158860      247 2011-02-08   \n",
       "2011-02-08   157661      247 2011-02-08   \n",
       "2011-02-10   158859      247 2011-02-10   \n",
       "2011-02-11    94294      247 2011-02-11   \n",
       "2011-02-13    55042      247 2011-02-13   \n",
       "...             ...      ...        ...   \n",
       "2011-11-06     2287      247 2011-11-06   \n",
       "2011-11-06    59869      247 2011-11-06   \n",
       "2011-11-08     8981      247 2011-11-08   \n",
       "2011-11-08    25976      247 2011-11-08   \n",
       "2011-11-08   158670      247 2011-11-08   \n",
       "2011-11-13   158666      247 2011-11-13   \n",
       "2011-11-14     1854      247 2011-11-14   \n",
       "2011-11-15    87885      247 2011-11-15   \n",
       "2011-11-18     5408      247 2011-11-18   \n",
       "2011-11-21      991      247 2011-11-21   \n",
       "2011-11-22     1748      247 2011-11-22   \n",
       "2011-11-23    10233      247 2011-11-23   \n",
       "2011-11-25   158662      247 2011-11-25   \n",
       "2011-11-27    15498      247 2011-11-27   \n",
       "2011-11-27    39509      247 2011-11-27   \n",
       "2011-12-04   115296      247 2011-12-04   \n",
       "2011-12-04    31537      247 2011-12-04   \n",
       "2011-12-05   128231      247 2011-12-05   \n",
       "2011-12-07    75458      247 2011-12-07   \n",
       "2011-12-08    16934      247 2011-12-08   \n",
       "2011-12-08    81721      247 2011-12-08   \n",
       "2011-12-14     5852      247 2011-12-14   \n",
       "2011-12-14    57936      247 2011-12-14   \n",
       "2011-12-15   158653      247 2011-12-15   \n",
       "2011-12-18   158652      247 2011-12-18   \n",
       "2011-12-18      987      247 2011-12-18   \n",
       "2011-12-27    29241      247 2011-12-27   \n",
       "2011-12-27   157645      247 2011-12-27   \n",
       "2011-12-29    95951      247 2011-12-29   \n",
       "2011-12-30   157365      247 2011-12-30   \n",
       "\n",
       "                                                       review  label  rating  \\\n",
       "date                                                                           \n",
       "2011-01-02  Coming from the Bay area where we do have some...      0     3.0   \n",
       "2011-01-05  This ain't no hole in the wall ramen spot. Thi...      0     4.0   \n",
       "2011-01-05  Whenever I have friends in own, this is one of...      1     4.0   \n",
       "2011-01-09  You come here to say you did. Food: Pork buns ...      0     3.0   \n",
       "2011-01-09  Joining a league of thousands...I am adding my...      0     4.0   \n",
       "2011-01-12  We ended up choosing Ippudo in the Village. Go...      0     4.0   \n",
       "2011-01-12  This place is an ABSOLUTE-MUST if you're visit...      0     5.0   \n",
       "2011-01-14  First time here... and I liked it!  The noodle...      0     4.0   \n",
       "2011-01-17  I was doubtful. I've had $1 ramen you buy in s...      0     4.0   \n",
       "2011-01-17    A must... Ramen is slammin... Worth the wait...      1     5.0   \n",
       "2011-01-18  Went back and got the Kogashi Miso Ramen, and ...      0     4.0   \n",
       "2011-01-18  I had lunch there on a Monday, I waited a tabl...      0     4.0   \n",
       "2011-01-23  When we got there a few days after Christmas, ...      0     4.0   \n",
       "2011-01-23  I don't know what everyone's hype is about Ipp...      1     3.0   \n",
       "2011-01-24  This is one of the best restaurants I've been ...      1     5.0   \n",
       "2011-01-24  I was there twice and the noodle dishes were g...      0     4.0   \n",
       "2011-01-25  I really love this place. I go here all the ti...      1     5.0   \n",
       "2011-01-25             Food are always fresh , U guys must go      1     3.0   \n",
       "2011-01-27  Came here with two friends, and we had to wait...      0     4.0   \n",
       "2011-01-27  GREAT rich, flavorful broth, and as expected w...      0     4.0   \n",
       "2011-01-28  Yum! This place opened my eyes to a new world ...      1     5.0   \n",
       "2011-02-02  Delicious! Most silent meal we ever had becaus...      1     4.0   \n",
       "2011-02-03  My brother and five of our friends went here a...      0     4.0   \n",
       "2011-02-06  Rich, creamy, and VERY satisfying tonkatsu ram...      0     4.0   \n",
       "2011-02-07  I went here over Christmas with my boyfriend a...      1     5.0   \n",
       "2011-02-08  Ippudo is great for a date or just a nice rame...      0     4.0   \n",
       "2011-02-08  the broth tastes like everything good in this ...      1     5.0   \n",
       "2011-02-10  Went here with a friend for lunch.  The pork b...      0     5.0   \n",
       "2011-02-11  The best ramen I've had in the US. I couldn't ...      0     5.0   \n",
       "2011-02-13  I'm definitely a fan.  Ok the price isn't the ...      0     4.0   \n",
       "...                                                       ...    ...     ...   \n",
       "2011-11-06  I've been to Ippudo upwards of 8 times now, an...      0     3.0   \n",
       "2011-11-06  OK Ippudo, after numerous visits taking all my...      0     4.0   \n",
       "2011-11-08  I waited for two hours, was bitched at by our ...      1     4.0   \n",
       "2011-11-08  There was only 2 of us on our party and we wen...      0     4.0   \n",
       "2011-11-08  Amazing...   One of my favorite NYC restaurant...      0     5.0   \n",
       "2011-11-13  Love this place every time I go. I'll keep it ...      0     5.0   \n",
       "2011-11-14  OK OK , everyone, don't get angry. I liked Ipp...      0     3.0   \n",
       "2011-11-15  Absolutely loved this place! From the greeting...      0     4.0   \n",
       "2011-11-18  You may balk at having to wait 60-90mins for a...      1     5.0   \n",
       "2011-11-21  I strongly advise you to NOT come here on a we...      0     4.0   \n",
       "2011-11-22  Yummy.  Ate here for lunch today. First the wa...      0     4.0   \n",
       "2011-11-23  My second time here.  To me, this place is mor...      0     3.0   \n",
       "2011-11-25  horrible service, awful hostess and very tight...      0     1.0   \n",
       "2011-11-27  Went a second time, got the same thing, still ...      0     5.0   \n",
       "2011-11-27  Ippudo has quickly distinguished itself from o...      0     4.0   \n",
       "2011-12-04  Very good ramen.  I like the spice and the noo...      1     4.0   \n",
       "2011-12-04  This place is good for classic ramen. The plac...      1     4.0   \n",
       "2011-12-05  Plan to have lunch early so you can be in line...      0     3.0   \n",
       "2011-12-07  The place was way overrated. It's not worth st...      1     2.0   \n",
       "2011-12-08  Ippudo is taste same taste between NYC and Jap...      1     4.0   \n",
       "2011-12-08  This place was great!  You've got to love a pl...      0     5.0   \n",
       "2011-12-14  Awesome Awesome Ramen. Anytime you go to a pla...      0     5.0   \n",
       "2011-12-14  Oh my God!  The best pork buns ever!  Not to m...      1     5.0   \n",
       "2011-12-15  Only four starts because it was a bit loud wit...      0     4.0   \n",
       "2011-12-18  I have to say....second time around with 2 yea...      0     3.0   \n",
       "2011-12-18  I swore I would never wait an hour standing in...      0     4.0   \n",
       "2011-12-27  I wish I had visited this place a lot more so ...      0     4.0   \n",
       "2011-12-27  Rainy day in NYC, had just spent 2 hours stand...      1     5.0   \n",
       "2011-12-29  I'm giving this 3 stars only because of the po...      0     3.0   \n",
       "2011-12-30  As a person grown up to love noodles, I must s...      1     2.0   \n",
       "\n",
       "            char_count  word_count  word_density  punctuation_count  ...  \\\n",
       "date                                                                 ...   \n",
       "2011-01-02         902         167      5.369048                 35  ...   \n",
       "2011-01-05         970         183      5.271739                 24  ...   \n",
       "2011-01-05         340          68      4.927536                  7  ...   \n",
       "2011-01-09        1228         222      5.506726                 49  ...   \n",
       "2011-01-09        2092         369      5.654054                 85  ...   \n",
       "2011-01-12         701         136      5.116788                 22  ...   \n",
       "2011-01-12        2311         423      5.450472                 74  ...   \n",
       "2011-01-14         607         118      5.100840                 22  ...   \n",
       "2011-01-17        1275         240      5.290456                 36  ...   \n",
       "2011-01-17          47           8      5.222222                  9  ...   \n",
       "2011-01-18         160          32      4.848485                  4  ...   \n",
       "2011-01-18         278          56      4.877193                 17  ...   \n",
       "2011-01-23         615         118      5.168067                 20  ...   \n",
       "2011-01-23         902         171      5.244186                 23  ...   \n",
       "2011-01-24         395          80      4.876543                 12  ...   \n",
       "2011-01-24         560         112      4.955752                 17  ...   \n",
       "2011-01-25         288          62      4.571429                  7  ...   \n",
       "2011-01-25          38           9      3.800000                  1  ...   \n",
       "2011-01-27         462          86      5.310345                 16  ...   \n",
       "2011-01-27         428          78      5.417722                 14  ...   \n",
       "2011-01-28         376          70      5.295775                 15  ...   \n",
       "2011-02-02         178          34      5.085714                  4  ...   \n",
       "2011-02-03        1070         213      5.000000                 25  ...   \n",
       "2011-02-06        1658         320      5.165109                 53  ...   \n",
       "2011-02-07         411          77      5.269231                  8  ...   \n",
       "2011-02-08         177          37      4.657895                  3  ...   \n",
       "2011-02-08         131          22      5.695652                  4  ...   \n",
       "2011-02-10         320          58      5.423729                 12  ...   \n",
       "2011-02-11         550         105      5.188679                 27  ...   \n",
       "2011-02-13         651         125      5.166667                 32  ...   \n",
       "...                ...         ...           ...                ...  ...   \n",
       "2011-11-06         626         124      5.008000                 18  ...   \n",
       "2011-11-06         480          94      5.052632                 16  ...   \n",
       "2011-11-08         165          32      5.000000                  8  ...   \n",
       "2011-11-08         947         190      4.958115                 34  ...   \n",
       "2011-11-08         159          29      5.300000                  6  ...   \n",
       "2011-11-13         112          23      4.666667                  7  ...   \n",
       "2011-11-14        1667         307      5.412338                 87  ...   \n",
       "2011-11-15         324          62      5.142857                  6  ...   \n",
       "2011-11-18         376          71      5.222222                 15  ...   \n",
       "2011-11-21        1315         249      5.260000                 38  ...   \n",
       "2011-11-22         252          48      5.142857                 13  ...   \n",
       "2011-11-23         369          65      5.590909                 17  ...   \n",
       "2011-11-25         120          20      5.714286                  6  ...   \n",
       "2011-11-27         355          70      5.000000                 16  ...   \n",
       "2011-11-27        1427         243      5.848361                 36  ...   \n",
       "2011-12-04         167          29      5.566667                  6  ...   \n",
       "2011-12-04         751         139      5.364286                 18  ...   \n",
       "2011-12-05        1611         304      5.281967                 41  ...   \n",
       "2011-12-07          87          17      4.833333                  3  ...   \n",
       "2011-12-08         201          36      5.432432                 12  ...   \n",
       "2011-12-08         995         183      5.407609                 36  ...   \n",
       "2011-12-14         893         177      5.016854                 29  ...   \n",
       "2011-12-14         165          32      5.000000                  9  ...   \n",
       "2011-12-15         480          87      5.454545                 16  ...   \n",
       "2011-12-18        1421         262      5.403042                 64  ...   \n",
       "2011-12-18         727         148      4.879195                 14  ...   \n",
       "2011-12-27         512         104      4.876190                 19  ...   \n",
       "2011-12-27         949         172      5.485549                 29  ...   \n",
       "2011-12-29        2316         437      5.287671                143  ...   \n",
       "2011-12-30        1819         336      5.397626                 36  ...   \n",
       "\n",
       "            upper_case_word_count  day_of_week user_id_no_of_review  \\\n",
       "date                                                                  \n",
       "2011-01-02                      9       Sunday                    1   \n",
       "2011-01-05                     11    Wednesday                    1   \n",
       "2011-01-05                      3    Wednesday                    1   \n",
       "2011-01-09                      8       Sunday                    1   \n",
       "2011-01-09                      4       Sunday                    1   \n",
       "2011-01-12                      3    Wednesday                    2   \n",
       "2011-01-12                     11    Wednesday                    2   \n",
       "2011-01-14                      5       Friday                    1   \n",
       "2011-01-17                      8       Monday                    3   \n",
       "2011-01-17                      1       Monday                    2   \n",
       "2011-01-18                      0      Tuesday                    1   \n",
       "2011-01-18                      4      Tuesday                    1   \n",
       "2011-01-23                      6       Sunday                    1   \n",
       "2011-01-23                      6       Sunday                    1   \n",
       "2011-01-24                      2       Monday                    2   \n",
       "2011-01-24                      6       Monday                    1   \n",
       "2011-01-25                      3      Tuesday                    1   \n",
       "2011-01-25                      1      Tuesday                    1   \n",
       "2011-01-27                      1     Thursday                    1   \n",
       "2011-01-27                      3     Thursday                    1   \n",
       "2011-01-28                      2       Friday                    1   \n",
       "2011-02-02                      0    Wednesday                    2   \n",
       "2011-02-03                      8     Thursday                    1   \n",
       "2011-02-06                     15       Sunday                    1   \n",
       "2011-02-07                      6       Monday                    1   \n",
       "2011-02-08                      0      Tuesday                    1   \n",
       "2011-02-08                      1      Tuesday                    1   \n",
       "2011-02-10                      0     Thursday                    1   \n",
       "2011-02-11                      4       Friday                    1   \n",
       "2011-02-13                      4       Sunday                    2   \n",
       "...                           ...          ...                  ...   \n",
       "2011-11-06                      3       Sunday                    1   \n",
       "2011-11-06                      7       Sunday                    3   \n",
       "2011-11-08                      1      Tuesday                    6   \n",
       "2011-11-08                     14      Tuesday                    1   \n",
       "2011-11-08                      1      Tuesday                    1   \n",
       "2011-11-13                      1       Sunday                    1   \n",
       "2011-11-14                     13       Monday                    2   \n",
       "2011-11-15                      0      Tuesday                    1   \n",
       "2011-11-18                      0       Friday                    5   \n",
       "2011-11-21                     16       Monday                    2   \n",
       "2011-11-22                      0      Tuesday                    4   \n",
       "2011-11-23                      0    Wednesday                    1   \n",
       "2011-11-25                      0       Friday                    1   \n",
       "2011-11-27                      2       Sunday                    2   \n",
       "2011-11-27                      0       Sunday                    1   \n",
       "2011-12-04                      2       Sunday                    3   \n",
       "2011-12-04                      2       Sunday                    2   \n",
       "2011-12-05                      9       Monday                    2   \n",
       "2011-12-07                      0    Wednesday                    2   \n",
       "2011-12-08                      3     Thursday                   11   \n",
       "2011-12-08                      6     Thursday                    1   \n",
       "2011-12-14                      8    Wednesday                    1   \n",
       "2011-12-14                      0    Wednesday                    3   \n",
       "2011-12-15                      4     Thursday                    1   \n",
       "2011-12-18                     25       Sunday                    1   \n",
       "2011-12-18                      4       Sunday                    1   \n",
       "2011-12-27                      6      Tuesday                    1   \n",
       "2011-12-27                      4      Tuesday                    1   \n",
       "2011-12-29                     11     Thursday                    1   \n",
       "2011-12-30                      2       Friday                    1   \n",
       "\n",
       "            user_id_ave_rating  user_id_ave_no_words  \\\n",
       "date                                                   \n",
       "2011-01-02            3.000000            167.000000   \n",
       "2011-01-05            4.000000            183.000000   \n",
       "2011-01-05            4.000000             68.000000   \n",
       "2011-01-09            3.000000            222.000000   \n",
       "2011-01-09            4.000000            369.000000   \n",
       "2011-01-12            3.500000            164.500000   \n",
       "2011-01-12            4.500000            321.000000   \n",
       "2011-01-14            4.000000            118.000000   \n",
       "2011-01-17            4.000000            138.000000   \n",
       "2011-01-17            4.500000             24.500000   \n",
       "2011-01-18            4.000000             32.000000   \n",
       "2011-01-18            4.000000             56.000000   \n",
       "2011-01-23            4.000000            118.000000   \n",
       "2011-01-23            3.000000            171.000000   \n",
       "2011-01-24            5.000000             85.500000   \n",
       "2011-01-24            4.000000            112.000000   \n",
       "2011-01-25            5.000000             62.000000   \n",
       "2011-01-25            3.000000              9.000000   \n",
       "2011-01-27            4.000000             86.000000   \n",
       "2011-01-27            4.000000             78.000000   \n",
       "2011-01-28            5.000000             70.000000   \n",
       "2011-02-02            4.000000             26.500000   \n",
       "2011-02-03            4.000000            213.000000   \n",
       "2011-02-06            4.000000            320.000000   \n",
       "2011-02-07            5.000000             77.000000   \n",
       "2011-02-08            4.000000             37.000000   \n",
       "2011-02-08            5.000000             22.000000   \n",
       "2011-02-10            5.000000             58.000000   \n",
       "2011-02-11            5.000000            105.000000   \n",
       "2011-02-13            3.000000            243.000000   \n",
       "...                        ...                   ...   \n",
       "2011-11-06            3.000000            124.000000   \n",
       "2011-11-06            3.333333            117.333333   \n",
       "2011-11-08            3.666667             67.833333   \n",
       "2011-11-08            4.000000            190.000000   \n",
       "2011-11-08            5.000000             29.000000   \n",
       "2011-11-13            5.000000             23.000000   \n",
       "2011-11-14            4.000000            387.500000   \n",
       "2011-11-15            4.000000             62.000000   \n",
       "2011-11-18            4.200000             72.800000   \n",
       "2011-11-21            4.000000            167.000000   \n",
       "2011-11-22            4.000000             86.750000   \n",
       "2011-11-23            3.000000             65.000000   \n",
       "2011-11-25            1.000000             20.000000   \n",
       "2011-11-27            4.500000            117.000000   \n",
       "2011-11-27            4.000000            243.000000   \n",
       "2011-12-04            4.333333             33.000000   \n",
       "2011-12-04            4.000000             92.500000   \n",
       "2011-12-05            3.500000            276.000000   \n",
       "2011-12-07            3.500000             22.000000   \n",
       "2011-12-08            3.181818             12.363636   \n",
       "2011-12-08            5.000000            183.000000   \n",
       "2011-12-14            5.000000            177.000000   \n",
       "2011-12-14            2.666667             51.000000   \n",
       "2011-12-15            4.000000             87.000000   \n",
       "2011-12-18            3.000000            262.000000   \n",
       "2011-12-18            4.000000            148.000000   \n",
       "2011-12-27            4.000000            104.000000   \n",
       "2011-12-27            5.000000            172.000000   \n",
       "2011-12-29            3.000000            437.000000   \n",
       "2011-12-30            2.000000            336.000000   \n",
       "\n",
       "            user_id_max_review_a_day  prod_id_no_of_review  \\\n",
       "date                                                         \n",
       "2011-01-02                         1                   235   \n",
       "2011-01-05                         1                   235   \n",
       "2011-01-05                         1                   235   \n",
       "2011-01-09                         1                   235   \n",
       "2011-01-09                         1                   235   \n",
       "2011-01-12                         1                   235   \n",
       "2011-01-12                         2                   235   \n",
       "2011-01-14                         1                   235   \n",
       "2011-01-17                         1                   235   \n",
       "2011-01-17                         1                   235   \n",
       "2011-01-18                         1                   235   \n",
       "2011-01-18                         1                   235   \n",
       "2011-01-23                         1                   235   \n",
       "2011-01-23                         1                   235   \n",
       "2011-01-24                         2                   235   \n",
       "2011-01-24                         1                   235   \n",
       "2011-01-25                         1                   235   \n",
       "2011-01-25                         1                   235   \n",
       "2011-01-27                         1                   235   \n",
       "2011-01-27                         1                   235   \n",
       "2011-01-28                         1                   235   \n",
       "2011-02-02                         2                   235   \n",
       "2011-02-03                         1                   235   \n",
       "2011-02-06                         1                   235   \n",
       "2011-02-07                         1                   235   \n",
       "2011-02-08                         1                   235   \n",
       "2011-02-08                         1                   235   \n",
       "2011-02-10                         1                   235   \n",
       "2011-02-11                         1                   235   \n",
       "2011-02-13                         1                   235   \n",
       "...                              ...                   ...   \n",
       "2011-11-06                         1                   235   \n",
       "2011-11-06                         2                   235   \n",
       "2011-11-08                         1                   235   \n",
       "2011-11-08                         1                   235   \n",
       "2011-11-08                         1                   235   \n",
       "2011-11-13                         1                   235   \n",
       "2011-11-14                         1                   235   \n",
       "2011-11-15                         1                   235   \n",
       "2011-11-18                         5                   235   \n",
       "2011-11-21                         1                   235   \n",
       "2011-11-22                         1                   235   \n",
       "2011-11-23                         1                   235   \n",
       "2011-11-25                         1                   235   \n",
       "2011-11-27                         1                   235   \n",
       "2011-11-27                         1                   235   \n",
       "2011-12-04                         3                   235   \n",
       "2011-12-04                         1                   235   \n",
       "2011-12-05                         1                   235   \n",
       "2011-12-07                         2                   235   \n",
       "2011-12-08                         5                   235   \n",
       "2011-12-08                         1                   235   \n",
       "2011-12-14                         1                   235   \n",
       "2011-12-14                         3                   235   \n",
       "2011-12-15                         1                   235   \n",
       "2011-12-18                         1                   235   \n",
       "2011-12-18                         1                   235   \n",
       "2011-12-27                         1                   235   \n",
       "2011-12-27                         1                   235   \n",
       "2011-12-29                         1                   235   \n",
       "2011-12-30                         1                   235   \n",
       "\n",
       "            prod_id_ave_rating  prod_id_ave_no_words  prod_id_max_review_a_day  \n",
       "date                                                                            \n",
       "2011-01-02            4.042553            118.948936                         4  \n",
       "2011-01-05            4.042553            118.948936                         4  \n",
       "2011-01-05            4.042553            118.948936                         4  \n",
       "2011-01-09            4.042553            118.948936                         4  \n",
       "2011-01-09            4.042553            118.948936                         4  \n",
       "2011-01-12            4.042553            118.948936                         4  \n",
       "2011-01-12            4.042553            118.948936                         4  \n",
       "2011-01-14            4.042553            118.948936                         4  \n",
       "2011-01-17            4.042553            118.948936                         4  \n",
       "2011-01-17            4.042553            118.948936                         4  \n",
       "2011-01-18            4.042553            118.948936                         4  \n",
       "2011-01-18            4.042553            118.948936                         4  \n",
       "2011-01-23            4.042553            118.948936                         4  \n",
       "2011-01-23            4.042553            118.948936                         4  \n",
       "2011-01-24            4.042553            118.948936                         4  \n",
       "2011-01-24            4.042553            118.948936                         4  \n",
       "2011-01-25            4.042553            118.948936                         4  \n",
       "2011-01-25            4.042553            118.948936                         4  \n",
       "2011-01-27            4.042553            118.948936                         4  \n",
       "2011-01-27            4.042553            118.948936                         4  \n",
       "2011-01-28            4.042553            118.948936                         4  \n",
       "2011-02-02            4.042553            118.948936                         4  \n",
       "2011-02-03            4.042553            118.948936                         4  \n",
       "2011-02-06            4.042553            118.948936                         4  \n",
       "2011-02-07            4.042553            118.948936                         4  \n",
       "2011-02-08            4.042553            118.948936                         4  \n",
       "2011-02-08            4.042553            118.948936                         4  \n",
       "2011-02-10            4.042553            118.948936                         4  \n",
       "2011-02-11            4.042553            118.948936                         4  \n",
       "2011-02-13            4.042553            118.948936                         4  \n",
       "...                        ...                   ...                       ...  \n",
       "2011-11-06            4.042553            118.948936                         4  \n",
       "2011-11-06            4.042553            118.948936                         4  \n",
       "2011-11-08            4.042553            118.948936                         4  \n",
       "2011-11-08            4.042553            118.948936                         4  \n",
       "2011-11-08            4.042553            118.948936                         4  \n",
       "2011-11-13            4.042553            118.948936                         4  \n",
       "2011-11-14            4.042553            118.948936                         4  \n",
       "2011-11-15            4.042553            118.948936                         4  \n",
       "2011-11-18            4.042553            118.948936                         4  \n",
       "2011-11-21            4.042553            118.948936                         4  \n",
       "2011-11-22            4.042553            118.948936                         4  \n",
       "2011-11-23            4.042553            118.948936                         4  \n",
       "2011-11-25            4.042553            118.948936                         4  \n",
       "2011-11-27            4.042553            118.948936                         4  \n",
       "2011-11-27            4.042553            118.948936                         4  \n",
       "2011-12-04            4.042553            118.948936                         4  \n",
       "2011-12-04            4.042553            118.948936                         4  \n",
       "2011-12-05            4.042553            118.948936                         4  \n",
       "2011-12-07            4.042553            118.948936                         4  \n",
       "2011-12-08            4.042553            118.948936                         4  \n",
       "2011-12-08            4.042553            118.948936                         4  \n",
       "2011-12-14            4.042553            118.948936                         4  \n",
       "2011-12-14            4.042553            118.948936                         4  \n",
       "2011-12-15            4.042553            118.948936                         4  \n",
       "2011-12-18            4.042553            118.948936                         4  \n",
       "2011-12-18            4.042553            118.948936                         4  \n",
       "2011-12-27            4.042553            118.948936                         4  \n",
       "2011-12-27            4.042553            118.948936                         4  \n",
       "2011-12-29            4.042553            118.948936                         4  \n",
       "2011-12-30            4.042553            118.948936                         4  \n",
       "\n",
       "[235 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['prod_id_no_of_review'] = training.groupby('prod_id')['prod_id'].transform('size') \n",
    "training['prod_id_ave_rating'] = training.groupby('prod_id')['rating'].transform('mean')\n",
    "training['prod_id_ave_no_words'] = training.groupby('prod_id')['word_count'].transform('mean')\n",
    "training['prod_id_max_review_a_day'] = training['prod_id_no_of_review']\n",
    "grouped = training.groupby('prod_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    training.loc[training.prod_id == name,'prod_id_max_review_a_day'] = df2\n",
    "\n",
    "testing['prod_id_no_of_review'] = testing.groupby('prod_id')['prod_id'].transform('size')\n",
    "testing['prod_id_ave_rating'] = testing.groupby('prod_id')['rating'].transform('mean')\n",
    "testing['prod_id_ave_no_words'] = testing.groupby('prod_id')['word_count'].transform('mean')\n",
    "testing['prod_id_max_review_a_day'] = testing['prod_id_no_of_review']\n",
    "grouped = testing.groupby('prod_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    testing.loc[testing.prod_id == name,'prod_id_max_review_a_day'] = df2\n",
    "\n",
    "training[:][training.prod_id==247].sort_index(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "final_testing['char_count'] = final_testing['review'].apply(len)\n",
    "final_testing['word_count'] = final_testing['review'].apply(lambda x: len(x.split()))\n",
    "final_testing['word_density'] = final_testing['char_count'] / (final_testing['word_count']+1)\n",
    "final_testing['punctuation_count'] = final_testing['review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation)))\n",
    "final_testing['title_word_count'] = final_testing['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "final_testing['upper_case_word_count'] = final_testing['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "final_testing.label[final_testing.label==1]=0\n",
    "final_testing.label[final_testing.label==-1]=1\n",
    "id_test=np.random.permutation(len(final_testing))\n",
    "final_testing=final_testing.iloc[id_test]\n",
    "test_y=final_testing.label\n",
    "\n",
    "final_testing['date.1'] = pd.to_datetime(final_testing['date.1'])\n",
    "final_testing['day_of_week'] = final_testing['date.1'].dt.day_name()\n",
    "dofw = final_testing.day_of_week.unique()\n",
    "for day in range(len(dofw)):\n",
    "    label=final_testing['label'][final_testing.day_of_week == dofw[day]]\n",
    "    fake=len(label[label==1])\n",
    "    real=len(label[label==0])\n",
    "       \n",
    "final_testing['user_id_no_of_review'] = final_testing.groupby('user_id')['user_id'].transform('size')\n",
    "final_testing['user_id_ave_rating'] = final_testing.groupby('user_id')['rating'].transform('mean')\n",
    "final_testing['user_id_ave_no_words'] = final_testing.groupby('user_id')['word_count'].transform('mean')\n",
    "final_testing['user_id_max_review_a_day'] = final_testing['user_id_no_of_review']\n",
    "grouped = final_testing.groupby('user_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    final_testing.loc[final_testing.user_id == name,'user_id_max_review_a_day'] = df2\n",
    "\n",
    "final_testing['prod_id_no_of_review'] = final_testing.groupby('prod_id')['prod_id'].transform('size')\n",
    "final_testing['prod_id_ave_rating'] = final_testing.groupby('prod_id')['rating'].transform('mean')\n",
    "final_testing['prod_id_ave_no_words'] = final_testing.groupby('prod_id')['word_count'].transform('mean')\n",
    "final_testing['prod_id_max_review_a_day'] = final_testing['prod_id_no_of_review']\n",
    "grouped = testing.groupby('prod_id')\n",
    "\n",
    "for name,group in grouped:\n",
    "    df2 = group.groupby('date').size().max()\n",
    "    final_testing.loc[final_testing.prod_id == name,'prod_id_max_review_a_day'] = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat=(np.array(minmax_scale([training['user_id']],axis=1)))\n",
    "valid_feat=(np.array(minmax_scale([testing['user_id']],axis=1)))\n",
    "test_feat=(np.array(minmax_scale([final_testing['user_id']],axis=1)))\n",
    "\n",
    "[train_feat,valid_feat,test_feat]=add_features(train_feat.T,valid_feat.T,test_feat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['total']=training.user_id.astype(str) + ' '+ training.prod_id.astype(str) + ' ' + training.rating.astype(str) + ' '+ \\\n",
    "training.user_id_no_of_review.astype(str) + ' ' + training.user_id_ave_rating.astype(str) + ' '+\\\n",
    "training.user_id_ave_no_words.astype(str) + ' ' + training.user_id_max_review_a_day.astype(str) + ' '+\\\n",
    "training.prod_id_no_of_review.astype(str) + ' ' + training.prod_id_ave_rating.astype(str) + ' '+\\\n",
    "training.prod_id_ave_no_words.astype(str) + ' ' + training.prod_id_max_review_a_day.astype(str) + ' '+\\\n",
    "training.day_of_week.astype(str) + ' '+training.review  \n",
    "\n",
    "\n",
    "testing['total']=testing.user_id.astype(str) + ' '+ testing.prod_id.astype(str) + ' ' + testing.rating.astype(str) + ' '+ \\\n",
    "testing.user_id_no_of_review.astype(str) + ' ' + testing.user_id_ave_rating.astype(str) + ' '+\\\n",
    "testing.user_id_ave_no_words.astype(str) + ' ' + testing.user_id_max_review_a_day.astype(str) + ' '+\\\n",
    "testing.prod_id_no_of_review.astype(str) + ' ' + testing.prod_id_ave_rating.astype(str) + ' '+\\\n",
    "testing.prod_id_ave_no_words.astype(str) + ' ' + testing.prod_id_max_review_a_day.astype(str) + ' '+\\\n",
    "testing.day_of_week.astype(str) + ' '+ testing.review  \n",
    "\n",
    "final_testing['total']=final_testing.user_id.astype(str) + ' '+ final_testing.prod_id.astype(str) + ' ' + final_testing.rating.astype(str) + ' '+ \\\n",
    "final_testing.user_id_no_of_review.astype(str) + ' ' + final_testing.user_id_ave_rating.astype(str) + ' '+\\\n",
    "final_testing.user_id_ave_no_words.astype(str) + ' ' + final_testing.user_id_max_review_a_day.astype(str) + ' '+\\\n",
    "final_testing.prod_id_no_of_review.astype(str) + ' ' + final_testing.prod_id_ave_rating.astype(str) + ' '+\\\n",
    "final_testing.prod_id_ave_no_words.astype(str) + ' ' + final_testing.prod_id_max_review_a_day.astype(str) + ' '+\\\n",
    "final_testing.day_of_week.astype(str) + ' '+ final_testing.review  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer\n",
    "porter = SnowballStemmer(\"english\")\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from scipy import sparse\n",
    "def apply_PCA(feature_vector_train, feature_vector_valid, n_components = 300):\n",
    "    # applys PCA\n",
    "    pca = PCA(n_components)\n",
    "    #pca = PCA(0.95)\n",
    "    pca.fit(feature_vector_train.toarray())\n",
    "    xtrain = pca.transform(feature_vector_train.toarray())    \n",
    "    #xtrain.shape\n",
    "    \n",
    "    #xvalid_count.shape\n",
    "    \n",
    "    xvalid = pca.transform(feature_vector_valid.toarray()) \n",
    "    feature_vector_train = sparse.csr_matrix(xtrain)\n",
    "    feature_vector_valid = sparse.csr_matrix(xvalid)    \n",
    "    \n",
    "    return [feature_vector_train, feature_vector_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2011-08-11    1\n",
       "2011-03-22    3\n",
       "2011-02-11    1\n",
       "2011-07-30    8\n",
       "2011-05-23    2\n",
       "Name: user_id_no_of_review, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale_feature(col):\n",
    "    x = col.values.astype(float)\n",
    "    # Create a minimum and maximum processor object\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()    \n",
    "    # Create an object to transform the data to fit minmax processor\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    col = x_scaled\n",
    "    return col\n",
    "\n",
    "training['user_id_no_of_review'].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000, stop_words='english')\n",
    "count_vect.fit(training.total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_count = count_vect.transform(training.total)\n",
    "xvalid_count = count_vect.transform(testing.total)\n",
    "xtest_count = count_vect.transform(final_testing.total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000, stop_words='english',min_df=5)\n",
    "tfidf_vect.fit(training.total)\n",
    "xtrain_tfidf =  tfidf_vect.transform(training.total)\n",
    "xvalid_tfidf =  tfidf_vect.transform(testing.total)\n",
    "xtest_tfidf =  tfidf_vect.transform(final_testing.total)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=5000, stop_words='english',min_df=5)\n",
    "tfidf_vect_ngram.fit(training.total)\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(training.total)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(testing.total)\n",
    "xtest_tfidf_ngram = tfidf_vect_ngram.transform(final_testing.total)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=5000, stop_words='english',min_df=5)\n",
    "tfidf_vect_ngram_chars.fit(training.total)\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(training.total) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(testing.total)\n",
    "xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(final_testing.total)\n",
    "\n",
    "#[xtrain_tfidf_ngram_chars_LR, xvalid_tfidf_ngram_chars_LR] = apply_PCA(xtrain_tfidf_ngram_chars, xvalid_tfidf_ngram_chars)\n",
    "#[xtrain_tfidf_ngram_chars_LR, xvalid_tfidf_ngram_chars_LR] = add_features(xtrain_tfidf_ngram_chars_LR, xvalid_tfidf_ngram_chars_LR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):      \n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "\n",
    "    # Predict the labels and probabilities\n",
    "    probs = classifier.predict_proba(feature_vector_valid)    \n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "\n",
    "    print('**Training Metrics**')\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(classifier.predict(feature_vector_train), label))\n",
    "\n",
    "    fpr_ll, tpr_ll, thresholds = metrics.roc_curve(label, classifier.predict_proba(feature_vector_train)[:,1])\n",
    "    auc_ll = metrics.roc_auc_score(label, classifier.predict_proba(feature_vector_train)[:,1])\n",
    "    print(\"Auc ROC is \",auc_ll)\n",
    "\n",
    "    precision_ll, recall_ll, thresholds = metrics.precision_recall_curve(label, classifier.predict_proba(feature_vector_train)[:,1])\n",
    "    auc_ll = metrics.auc(recall_ll, precision_ll)\n",
    "    print(\"Auc PRC is \",auc_ll)\n",
    "    f1_ll = metrics.f1_score(label, classifier.predict(feature_vector_train))\n",
    "    print(\"F1 score is\",f1_ll)\n",
    "    print(\"Log loss is \",metrics.log_loss(label,classifier.predict_proba(feature_vector_train)[:,1]))\n",
    "    \n",
    "    return [predictions,metrics.accuracy_score(predictions, test_y),probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=training.label\n",
    "valid_y=testing.label\n",
    "test_y = final_testing.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Training Metrics**\n",
      "Accuracy:  0.8602121539014743\n",
      "Auc ROC is  0.93870498571172\n",
      "Auc PRC is  0.9348487685610788\n",
      "F1 score is 0.8637518619118548\n",
      "Log loss is  0.3425401953329953\n",
      "LR, Count Vectors:  0.6238\n",
      "**Training Metrics**\n",
      "Accuracy: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.7683387270765911\n",
      "Auc ROC is  0.8454606572233814\n",
      "Auc PRC is  0.8340128534462996\n",
      "F1 score is 0.7707907142221828\n",
      "Log loss is  0.5192613735209055\n",
      "LR, WordLevel TF-IDF:  0.661\n",
      "**Training Metrics**\n",
      "Accuracy:  0.7734627831715211\n",
      "Auc ROC is  0.8499034647317203\n",
      "Auc PRC is  0.839963129808531\n",
      "F1 score is 0.7733812949640289\n",
      "Log loss is  0.5114531959848215\n",
      "LR, N-Gram Vectors:  0.6632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Training Metrics**\n",
      "Accuracy:  0.6639697950377562\n",
      "Auc ROC is  0.7330713524415238\n",
      "Auc PRC is  0.7151775566356708\n",
      "F1 score is 0.6439999999999999\n",
      "Log loss is  0.6179907620419454\n",
      "LR, CharLevel Vectors:  0.6568\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "[prediction,accuracy,probs] = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xtest_count)\n",
    "print (\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "[prediction,accuracy,probs] = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "print (\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "[prediction,accuracy,probs] = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "print (\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "[prediction,accuracy,probs] = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)\n",
    "print (\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Training Metrics**\n",
      "Accuracy:  0.7056814095649047\n",
      "Auc ROC is  0.7874895865133015\n",
      "Auc PRC is  0.776555252507865\n",
      "F1 score is 0.7378702962369896\n",
      "Log loss is  1.3033363374616496\n",
      "NB, Count Vectors:  0.6445\n",
      "**Training Metrics**\n",
      "Accuracy:  0.7278856526429341\n",
      "Auc ROC is  0.8010650040774709\n",
      "Auc PRC is  0.7917583280201231\n",
      "F1 score is 0.7386687386687386\n",
      "Log loss is  0.5605882290270958\n",
      "NB, WordLevel TF-IDF:  0.6585\n",
      "**Training Metrics**\n",
      "Accuracy:  0.709277238403452\n",
      "Auc ROC is  0.776993541860374\n",
      "Auc PRC is  0.7598256023843226\n",
      "F1 score is 0.7163157894736841\n",
      "Log loss is  0.5693624101845238\n",
      "NB, N-Gram Vectors:  0.6572\n",
      "**Training Metrics**\n",
      "Accuracy:  0.6094030924128011\n",
      "Auc ROC is  0.6638877542827019\n",
      "Auc PRC is  0.6463566814828039\n",
      "F1 score is 0.5648472709063596\n",
      "Log loss is  0.6566085906905085\n",
      "NB, CharLevel Vectors:  0.6119\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "[prediction,accuracy,probs] = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xtest_count)\n",
    "print (\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "[prediction,accuracy,probs] = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "print (\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "[prediction,accuracy,probs] = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "print (\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "[prediction,accuracy,probs] = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)\n",
    "print (\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = xtrain_count\n",
    "y_train = training.label\n",
    "x_val = xvalid_count\n",
    "y_val = testing.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate is:  1\n",
      "Training Done\n",
      "Learning Rate is:  0.5\n",
      "Training Done\n",
      "Learning Rate is:  0.25\n",
      "Training Done\n",
      "Learning Rate is:  0.1\n",
      "Training Done\n",
      "Learning Rate is:  0.05\n",
      "Training Done\n",
      "Learning Rate is:  0.01\n",
      "Training Done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for eta in learning_rates:\n",
    "    print(\"Learning Rate is: \", eta)\n",
    "    model = GradientBoostingClassifier(learning_rate=eta)\n",
    "    model.fit(x_train, y_train)\n",
    "    train_pred = model.predict(x_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = model.predict(x_val)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_val, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "    print(\"Training Done\")\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(learning_rates, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(learning_rates, test_results, 'r', label='Val AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('learning rate')\n",
    "plt.savefig('Learing Rates Tuning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate chosen to be 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Estimators is:  1\n",
      "Training Done\n",
      "Number of Estimators is:  2\n",
      "Training Done\n",
      "Number of Estimators is:  4\n",
      "Training Done\n",
      "Number of Estimators is:  8\n",
      "Training Done\n",
      "Number of Estimators is:  16\n",
      "Training Done\n",
      "Number of Estimators is:  32\n",
      "Training Done\n",
      "Number of Estimators is:  64\n",
      "Training Done\n",
      "Number of Estimators is:  100\n",
      "Training Done\n",
      "Number of Estimators is:  200\n",
      "Training Done\n",
      "Number of Estimators is:  500\n",
      "Training Done\n",
      "Number of Estimators is:  1000\n",
      "Training Done\n",
      "Number of Estimators is:  1500\n",
      "Training Done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200, 500, 1000, 1500]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for estimator in n_estimators:\n",
    "    print(\"Number of Estimators is: \", estimator)\n",
    "    model = GradientBoostingClassifier(n_estimators=estimator)\n",
    "    print(\"Training Done\")\n",
    "    model.fit(x_train, y_train)\n",
    "    train_pred = model.predict(x_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = model.predict(x_val)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_val, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(n_estimators, test_results, 'r',  label='Val AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.savefig('n_estimators tuning.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of estimators chosen to be 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth is:  1.0\n",
      "Training Done\n",
      "Max Depth is:  5.0\n",
      "Training Done\n",
      "Max Depth is:  9.0\n",
      "Training Done\n",
      "Max Depth is:  13.0\n",
      "Training Done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 13, 4, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "    print(\"Max Depth is: \", max_depth)\n",
    "    model = GradientBoostingClassifier(max_depth=max_depth)\n",
    "    print(\"Training Done\")\n",
    "    model.fit(x_train, y_train)\n",
    "    train_pred = model.predict(x_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = model.predict(x_val)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_val, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "line1, = plt.plot(max_depths, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label='Val AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.savefig('Max Depth Tuning.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree Depth chosen to be 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxiumum Features is:  1\n",
      "Training Done\n",
      "Maxiumum Features is:  501\n",
      "Training Done\n",
      "Maxiumum Features is:  1001\n",
      "Training Done\n",
      "Maxiumum Features is:  1501\n",
      "Training Done\n",
      "Maxiumum Features is:  2001\n",
      "Training Done\n",
      "Maxiumum Features is:  2501\n",
      "Training Done\n",
      "Maxiumum Features is:  3001\n",
      "Training Done\n",
      "Maxiumum Features is:  3501\n",
      "Training Done\n",
      "Maxiumum Features is:  4001\n",
      "Training Done\n",
      "Maxiumum Features is:  4501\n",
      "Training Done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_features = list(range(1,x_train.shape[1], int(x_train.shape[1] / 10)))\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_feature in max_features:\n",
    "    print(\"Maxiumum Features is: \", max_feature)\n",
    "    model = GradientBoostingClassifier(max_features=max_feature)\n",
    "    model.fit(x_train, y_train)\n",
    "    train_pred = model.predict(x_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = model.predict(x_val)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_val, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "    print(\"Training Done\")\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_features, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(max_features, test_results, 'r', label='Val AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('max features')\n",
    "plt.savefig('Max Features Tuning.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose 500 Max Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=training.label\n",
    "valid_y=testing.label\n",
    "test_y = final_testing.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3691            5.36s\n",
      "         2           1.3404            4.94s\n",
      "         3           1.3274            4.45s\n",
      "         4           1.3154            4.25s\n",
      "         5           1.3047            3.93s\n",
      "         6           1.2949            3.71s\n",
      "         7           1.2835            3.55s\n",
      "         8           1.2748            3.40s\n",
      "         9           1.2649            3.34s\n",
      "        10           1.2566            3.39s\n",
      "        20           1.1842            2.79s\n",
      "        30           1.1390            2.47s\n",
      "        40           1.1028            2.43s\n",
      "        50           1.0723            2.19s\n",
      "        60           1.0484            2.04s\n",
      "        70           1.0249            1.87s\n",
      "        80           1.0034            1.71s\n",
      "        90           0.9807            1.58s\n",
      "       100           0.9640            1.43s\n",
      "       200           0.8311            0.00s\n",
      "**Training Metrics**\n",
      "Accuracy:  0.8482560230133046\n",
      "Auc ROC is  0.9286479948631756\n",
      "Auc PRC is  0.9203695156098646\n",
      "F1 score is 0.8559235233868215\n",
      "Log loss is  0.4155685644700365\n",
      "GB, Count Vectors:  0.6419\n",
      "Auc ROC is  0.6968662\n",
      "Auc PRC is  0.6655164116883323\n",
      "F1 score is 0.6688858067498845\n",
      "Log loss is  0.6348865771175947\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting on Count Vectors\n",
    "Grad_Boosting = GradientBoostingClassifier(max_features=150, max_depth=5, n_estimators=200, learning_rate=0.25, verbose = 1)\n",
    "                                                                    \n",
    "[prediction,accuracy,probs] = train_model(Grad_Boosting, xtrain_count, train_y, xtest_count)\n",
    "print(\"GB, Count Vectors: \", accuracy)\n",
    "\n",
    "fpr_ll, tpr_ll, thresholds = metrics.roc_curve(test_y, probs[:,1])\n",
    "auc_ll = metrics.roc_auc_score(test_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc_ll)\n",
    "\n",
    "precision_ll, recall_ll, thresholds = metrics.precision_recall_curve(test_y, probs[:,1])\n",
    "auc_ll = metrics.auc(recall_ll, precision_ll)\n",
    "print(\"Auc PRC is \",auc_ll)\n",
    "f1_ll = metrics.f1_score(test_y, prediction)\n",
    "print(\"F1 score is\",f1_ll)\n",
    "print(\"Log loss is \",metrics.log_loss(test_y,probs[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3630            5.95s\n",
      "         2           1.3435            5.83s\n",
      "         3           1.3215            6.09s\n",
      "         4           1.2958            5.96s\n",
      "         5           1.2775            5.64s\n",
      "         6           1.2615            5.32s\n",
      "         7           1.2500            5.42s\n",
      "         8           1.2334            5.43s\n",
      "         9           1.2231            5.35s\n",
      "        10           1.2152            5.23s\n",
      "        20           1.1349            4.57s\n",
      "        30           1.0793            4.26s\n",
      "        40           1.0346            3.96s\n",
      "        50           0.9972            3.75s\n",
      "        60           0.9685            3.46s\n",
      "        70           0.9407            3.12s\n",
      "        80           0.9181            2.84s\n",
      "        90           0.8964            2.57s\n",
      "       100           0.8755            2.37s\n",
      "       200           0.7129            0.00s\n",
      "**Training Metrics**\n",
      "Accuracy:  0.9129809421071557\n",
      "Auc ROC is  0.9726464873562202\n",
      "Auc PRC is  0.9731911661327719\n",
      "F1 score is 0.9128399063569242\n",
      "Log loss is  0.3564408761699996\n",
      "GB, N-Gram Vectors:  0.6469\n",
      "Auc ROC is  0.69996448\n",
      "Auc PRC is  0.6740892663575573\n",
      "F1 score is 0.6650858389452717\n",
      "Log loss is  0.6436728534596168\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting on Ngram Level TF IDF Vectors\n",
    "[prediction,accuracy,probs] = train_model(Grad_Boosting, xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "print (\"GB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "fpr_ll, tpr_ll, thresholds = metrics.roc_curve(test_y, probs[:,1])\n",
    "auc_ll = metrics.roc_auc_score(test_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc_ll)\n",
    "\n",
    "precision_ll, recall_ll, thresholds = metrics.precision_recall_curve(test_y, probs[:,1])\n",
    "auc_ll = metrics.auc(recall_ll, precision_ll)\n",
    "print(\"Auc PRC is \",auc_ll)\n",
    "f1_ll = metrics.f1_score(test_y, prediction)\n",
    "print(\"F1 score is\",f1_ll)\n",
    "print(\"Log loss is \",metrics.log_loss(test_y,probs[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3619            4.96s\n",
      "         2           1.3396            4.44s\n",
      "         3           1.3226            5.11s\n",
      "         4           1.3101            4.69s\n",
      "         5           1.2932            4.40s\n",
      "         6           1.2805            4.19s\n",
      "         7           1.2690            4.07s\n",
      "         8           1.2571            3.97s\n",
      "         9           1.2474            3.89s\n",
      "        10           1.2387            3.90s\n",
      "        20           1.1654            3.45s\n",
      "        30           1.1168            3.14s\n",
      "        40           1.0815            3.02s\n",
      "        50           1.0451            2.94s\n",
      "        60           1.0158            2.77s\n",
      "        70           0.9878            2.56s\n",
      "        80           0.9637            2.35s\n",
      "        90           0.9398            2.14s\n",
      "       100           0.9223            1.98s\n",
      "       200           0.7677            0.00s\n",
      "**Training Metrics**\n",
      "Accuracy:  0.8937432578209277\n",
      "Auc ROC is  0.9631561046144401\n",
      "Auc PRC is  0.9625981547144554\n",
      "F1 score is 0.8944831280128549\n",
      "Log loss is  0.38383303552624465\n",
      "GB, Testing, WordLevel TF-IDF:  0.6319\n",
      "Auc ROC is  0.68286998\n",
      "Auc PRC is  0.6553540133035907\n",
      "F1 score is 0.6538135991723879\n",
      "Log loss is  0.6492897793600854\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting on Word Level TF IDF Vectors\n",
    "[prediction,accuracy,probs] = train_model(Grad_Boosting, xtrain_tfidf, train_y, xtest_tfidf)\n",
    "print (\"GB, Testing, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "fpr_ll, tpr_ll, thresholds = metrics.roc_curve(test_y, probs[:,1])\n",
    "auc_ll = metrics.roc_auc_score(test_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc_ll)\n",
    "\n",
    "precision_ll, recall_ll, thresholds = metrics.precision_recall_curve(test_y, probs[:,1])\n",
    "auc_ll = metrics.auc(recall_ll, precision_ll)\n",
    "print(\"Auc PRC is \",auc_ll)\n",
    "f1_ll = metrics.f1_score(test_y, prediction)\n",
    "print(\"F1 score is\",f1_ll)\n",
    "print(\"Log loss is \",metrics.log_loss(test_y,probs[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Training Metrics**\n",
      "Accuracy:  0.8124775260697591\n",
      "Auc ROC is  0.8934282187355224\n",
      "Auc PRC is  0.894655593015925\n",
      "F1 score is 0.8128476583527723\n",
      "Log loss is  0.5010116841266111\n",
      "NB, CharLevel Vectors:  0.6474\n",
      "Auc ROC is  0.70315032\n",
      "Auc PRC is  0.6748334447115296\n",
      "F1 score is 0.6680474486913952\n",
      "Log loss is  0.6277376648078784\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting on Character Level TF IDF Vectors\n",
    "[prediction,accuracy,probs] = train_model(GradientBoostingClassifier(max_features=150, max_depth=5, n_estimators=64, learning_rate=0.1), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)\n",
    "print (\"NB, CharLevel Vectors: \", accuracy)\n",
    "\n",
    "fpr_ll, tpr_ll, thresholds = metrics.roc_curve(test_y, probs[:,1])\n",
    "auc_ll = metrics.roc_auc_score(test_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc_ll)\n",
    "\n",
    "precision_ll, recall_ll, thresholds = metrics.precision_recall_curve(test_y, probs[:,1])\n",
    "auc_ll = metrics.auc(recall_ll, precision_ll)\n",
    "print(\"Auc PRC is \",auc_ll)\n",
    "f1_ll = metrics.f1_score(test_y, prediction)\n",
    "print(\"F1 score is\",f1_ll)\n",
    "print(\"Log loss is \",metrics.log_loss(test_y,probs[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):      \n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "\n",
    "    # Predict the labels and probabilities\n",
    "    probs = classifier.predict_proba(feature_vector_valid)    \n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "\n",
    "    print('**Training Metrics**')\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(classifier.predict(feature_vector_train), label))\n",
    "\n",
    "    fpr_ll, tpr_ll, thresholds = metrics.roc_curve(label, classifier.predict_proba(feature_vector_train)[:,1])\n",
    "    auc_ll = metrics.roc_auc_score(label, classifier.predict_proba(feature_vector_train)[:,1])\n",
    "    print(\"Auc ROC is \",auc_ll)\n",
    "\n",
    "    precision_ll, recall_ll, thresholds = metrics.precision_recall_curve(label, classifier.predict_proba(feature_vector_train)[:,1])\n",
    "    auc_ll = metrics.auc(recall_ll, precision_ll)\n",
    "    print(\"Auc PRC is \",auc_ll)\n",
    "    f1_ll = metrics.f1_score(label, classifier.predict(feature_vector_train))\n",
    "    print(\"F1 score is\",f1_ll)\n",
    "    print(\"Log loss is \",metrics.log_loss(label,classifier.predict_proba(feature_vector_train)[:,1]))\n",
    "    \n",
    "    return [predictions,metrics.accuracy_score(predictions, valid_y),probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[prediction,accuracy,probs] = train_model(Grad_Boosting, xtrain_count, valid_y, xvalid_count)\n",
    "print(\"GB, Count Vectors: \", accuracy)\n",
    "\n",
    "fpr_ll, tpr_ll, thresholds = metrics.roc_curve(valid_y, probs[:,1])\n",
    "auc_ll = metrics.roc_auc_score(valid_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc_ll)\n",
    "\n",
    "precision_ll, recall_ll, thresholds = metrics.precision_recall_curve(valid_y, probs[:,1])\n",
    "auc_ll = metrics.auc(recall_ll, precision_ll)\n",
    "print(\"Auc PRC is \",auc_ll)\n",
    "f1_ll = metrics.f1_score(valid_y, prediction)\n",
    "print(\"F1 score is\",f1_ll)\n",
    "print(\"Log loss is \",metrics.log_loss(valid_y,probs[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3454           13.70s\n",
      "         2           1.3103           13.04s\n",
      "         3           1.2838           11.59s\n",
      "         4           1.2641           11.68s\n",
      "         5           1.2430           11.51s\n",
      "         6           1.2242           11.03s\n",
      "         7           1.2094           11.05s\n",
      "         8           1.1985           10.65s\n",
      "         9           1.1868           10.65s\n",
      "        10           1.1771           10.67s\n",
      "        20           1.0982            9.58s\n",
      "        30           1.0514            8.89s\n",
      "        40           1.0097            8.03s\n",
      "        50           0.9751            7.48s\n",
      "        60           0.9470            6.86s\n",
      "        70           0.9199            6.30s\n",
      "        80           0.8963            5.77s\n",
      "        90           0.8696            5.27s\n",
      "       100           0.8458            4.77s\n",
      "       200           0.6787            0.00s\n",
      "**Training Metrics**\n",
      "Accuracy:  0.9243078029485796\n",
      "Auc ROC is  0.9795335953982701\n",
      "Auc PRC is  0.9803696683770309\n",
      "F1 score is 0.9240072202166065\n",
      "Log loss is  0.3393520199392392\n",
      "GB, N-Gram Vectors:  0.6425\n",
      "Auc ROC is  0.684679\n",
      "Auc PRC is  0.6648026135823273\n",
      "F1 score is 0.6635294117647059\n",
      "Log loss is  0.658979734706051\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting on Ngram Level TF IDF Vectors\n",
    "[prediction,accuracy,probs] = train_model(Grad_Boosting, xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"GB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "fpr_ll, tpr_ll, thresholds = metrics.roc_curve(valid_y, probs[:,1])\n",
    "auc_ll = metrics.roc_auc_score(valid_y, probs[:,1])\n",
    "print(\"Auc ROC is \",auc_ll)\n",
    "\n",
    "precision_ll, recall_ll, thresholds = metrics.precision_recall_curve(valid_y, probs[:,1])\n",
    "auc_ll = metrics.auc(recall_ll, precision_ll)\n",
    "print(\"Auc PRC is \",auc_ll)\n",
    "f1_ll = metrics.f1_score(valid_y, prediction)\n",
    "print(\"F1 score is\",f1_ll)\n",
    "print(\"Log loss is \",metrics.log_loss(valid_y,probs[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from scipy import stats\n",
    "n=10\n",
    "acc=np.zeros(n)\n",
    "for i in range(n):\n",
    "    ind = resample(np.arange(len(final_testing.label)),replace=False,n_samples=2000)\n",
    "    xtest_tfidf_sample =  tfidf_vect.transform(final_testing.total[ind])\n",
    "    [prediction,accuracy,probs] = train_model(Grad_Boosting, xtrain_count, train_y, xtest_tfidf_sample, final_testing.label[ind])\n",
    "    acc[i]=accuracy\n",
    "print(stats.describe(acc))\n",
    "print(\"Std error is \",np.std(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
